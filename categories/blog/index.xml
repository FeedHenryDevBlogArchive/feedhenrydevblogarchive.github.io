<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Archive of FeedHenry Developer Blog 2012-2016</title>
    <link>http://feedhenrydevblogarchive.github.io/categories/blog/</link>
    <description>Recent content in Blog on Archive of FeedHenry Developer Blog 2012-2016</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Dec 2015 13:19:42 +0000</lastBuildDate>
    <atom:link href="http://feedhenrydevblogarchive.github.io/categories/blog/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Madrid Hackathon</title>
      <link>http://feedhenrydevblogarchive.github.io/madrid-hackathon/</link>
      <pubDate>Mon, 07 Dec 2015 13:19:42 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/madrid-hackathon/</guid>
      <description>&lt;p&gt;In Madrid, in a cool location in the centre of the city, Red Hat sponsored a IoT hackathon, 3 groups used RHMAP (Red Hat Mobile Application Platform) to build their entry for the competition. Over the course of two days (19 - 20th November), 11 groups and 6 individuals battled to find out who could build the best application.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_22_36_23_Rich_LI.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_22_36_23_Rich_LI.jpg&#34; alt=&#34;Windows phone_20151119_22_36_23_Rich_LI&#34; /&gt;&lt;/a&gt; &lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_10_39_06_Rich_LI.jpg&#34; alt=&#34;Windows phone_20151119_10_39_06_Rich_LI&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We where there to get them going and help where needed. For most of them doing anything mobile or IoT was completely new, but they had some experience with Node.js, once we explained them how things globally worked and shown them how to build a simple &amp;ldquo;Hello World&amp;rdquo; they where off. Remarkably, little help was needed the most questions we got where: &amp;ldquo;how do I do &amp;lsquo;xyz&amp;rsquo;&amp;rdquo; or &amp;ldquo;what is the best approach to add a feature like this&amp;rdquo;. Although I had explained that you could develop / run things locally some contestants where comfortable using a online approach developing locally and testing the app in the &amp;lsquo;App Preview&amp;rsquo; window.&lt;/p&gt;

&lt;p&gt;It wasn&amp;rsquo;t all work, there was some entertainment as well, there where some guys making jokes and some presentations about the possible future of IoT. Everything that happened was documented with some sketch notes. My portrait is also on it:&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_20_45_17_Rich_LI.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_20_45_17_Rich_LI.jpg&#34; alt=&#34;Windows phone_20151119_20_45_17_Rich_LI&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/Windows-phone_20151119_10_39_06_Rich_LI.jpg&#34;&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One of &amp;ldquo;our&amp;rdquo; teams won the big prize of 6000 euros, they got 2 checks like the one in the picture. As you can see from the eyes they pulled an &amp;ldquo;all nighter&amp;rdquo; to get something cool in the end.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/20151120_123940.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/11/20151120_123940.jpg&#34; alt=&#34;20151120_123940&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So a very successful and cool event, for us an opportunity to see how easy it is to get going on the platform and get ideas to improve the getting started. Till next year.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AeroGear quick start push Templates</title>
      <link>http://feedhenrydevblogarchive.github.io/aerogear-push-templates/</link>
      <pubDate>Wed, 10 Jun 2015 13:29:44 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/aerogear-push-templates/</guid>
      <description>&lt;p&gt;Currently in software development the biggest challenge is integrating. A lot of what we do involves integrating with other platforms or libraries. Knowing how to integrate is important, so here I&amp;rsquo;m going to show how to integrate the Unified Push Server (UPS) with Feedhenry, for adding push notification support. To make things even easier we created a Feedhenry Template that you can use as a starting point for your application that contains all the parts you&amp;rsquo;ll need.&lt;/p&gt;

&lt;p&gt;To illustrate how to use the FeedHenry Template for push notifications, you will build a set of sample applications for receiving sports news. You will use a centralized cloud application that integrates with both a push server as well as any client applications. The centralized cloud app contains various categories (i.e. different sports) and news stories associated with one or more categories. There are also two client applications:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Console web application: Let administrators create and update the category list, as well as create news stories on the centralized cloud app&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mobile application: Lets users subscribe to any of the available categories and receive a push notification whenever a new story is posted with that category&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To build a project based on this template:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a new project.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Click &lt;strong&gt;Sample Projects&lt;/strong&gt;, and then find the Project named: &lt;strong&gt;Push Hello World&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Click select type a name, and then click &lt;strong&gt;create&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/1.png&#34; alt=&#34;1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you have three apps one Cloud Code App and two Client Apps.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/5.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/5.png&#34; alt=&#34;5&#34; /&gt;&lt;/a&gt;
The &lt;em&gt;Push Cloud App&lt;/em&gt; is a simple server-side CRUD application for categories. The &lt;em&gt;Push Console App&lt;/em&gt; is a &amp;ldquo;management inteface&amp;rdquo; where you create and delete these categories. These categories are used by the &lt;em&gt;Push Notifications Mobile Client&lt;/em&gt; to &amp;ldquo;subscribe&amp;rdquo; to. For example I have a sports news site and I push messages about different sports to the mobile users. The users &lt;em&gt;subscribe&lt;/em&gt; to different sports they want to receive notifications about.&lt;/p&gt;

&lt;p&gt;With this generated project all that is left to do is connect the Unified Push Server to this project, first go to openshift.com and create an UPS instance, search on AeroGear pick a name and &amp;ldquo;Create Application&amp;rdquo;. For more information on how to set up a unified push server on Openshift have a look at the &lt;a href=&#34;https://aerogear.org/docs/unifiedpush/ups_userguide/index/#openshift&#34;&gt;AeroGear documentation&lt;/a&gt;. Now you have a running UPS on Openshift you need to login and create an &amp;ldquo;application&amp;rdquo; that will be used by your Feedhenry apps to send push notifications. Note down the &lt;code&gt;Application ID&lt;/code&gt;, &lt;code&gt;Master Secret&lt;/code&gt; and the &lt;code&gt;Server URL&lt;/code&gt; as we going to need those later on.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/10.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/10.png&#34; alt=&#34;10&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For the clients that we want to use (e.g. Android iOS) we need to create variants, for more information on how to do this have a look at the UPS documentation for &lt;a href=&#34;https://aerogear.org/docs/unifiedpush/aerogear-push-android/&#34;&gt;Android&lt;/a&gt; and &lt;a href=&#34;https://aerogear.org/docs/unifiedpush/aerogear-push-ios/&#34;&gt;iOS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Next we need to do two things we need create a &amp;ldquo;Service connector&amp;rdquo; for UPS and we need to tell the Cloud App the &lt;code&gt;GUID&lt;/code&gt; of the &amp;ldquo;Service connector&amp;rdquo; so that it can use this to send messages to UPS. First we setup the &amp;ldquo;Service connector&amp;rdquo; to connect to our openshift UPS instance, go to the &lt;code&gt;Services &amp;amp;amp; APIs&lt;/code&gt; tab and click &lt;code&gt;Provision mBaaS Service/API&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/3.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/3.png&#34; alt=&#34;3&#34; /&gt;&lt;/a&gt;
Then choose &lt;code&gt;AeroGear Push Service&lt;/code&gt;, give it a name and click &lt;code&gt;Next&lt;/code&gt;, fill in the &lt;code&gt;Server URL&lt;/code&gt;, &lt;code&gt;Application ID&lt;/code&gt; and &lt;code&gt;Master Secret&lt;/code&gt; and click &lt;code&gt;Next&lt;/code&gt; now it will create your &amp;ldquo;Service connector&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/7.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/7.png&#34; alt=&#34;7&#34; /&gt;&lt;/a&gt;
After that is done go back to your project, here we need to add the service so that we can use it click the &amp;ldquo;+&amp;rdquo; in the mBaas Services box in the overview page:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/2.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/2.png&#34; alt=&#34;2&#34; /&gt;&lt;/a&gt;
Select the created &amp;ldquo;Service connector&amp;rdquo; and then the &amp;ldquo;Associate Service&amp;rdquo; button. Now you&amp;rsquo;ll see the &amp;ldquo;Service Connector&amp;rdquo; in the &amp;ldquo;mBaas Services&amp;rdquo; column. Let&amp;rsquo;s configure the &amp;ldquo;Cloud App&amp;rdquo; to use this &amp;ldquo;Service Connector&amp;rdquo;, for that we need to the GUID of the &amp;ldquo;Service Connector&amp;rdquo;, click on it and you will see the info page:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/4.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/4.png&#34; alt=&#34;4&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On the info page copy the &lt;code&gt;Service ID&lt;/code&gt; and under access control add you project, then click save.&lt;/p&gt;

&lt;p&gt;Then in the project click on the &amp;ldquo;Push Cloud App&amp;rdquo; and select &amp;ldquo;Environment variables&amp;rdquo; from the sidebar. Click &amp;ldquo;Add Variable&amp;rdquo; and enter &lt;code&gt;AEROGEAR_SERVICE_GUID&lt;/code&gt; for name and paste the &lt;code&gt;Service ID&lt;/code&gt; you copied earlier for the &amp;ldquo;Development&amp;rdquo; label. Next click on &amp;ldquo;Push Environment Variables&amp;rdquo; to publish these.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/6.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/6.png&#34; alt=&#34;6&#34; /&gt;&lt;/a&gt;
Now that that is all setup, the &amp;ldquo;Cloud App&amp;rdquo; can use the &amp;ldquo;GUID&amp;rdquo; to fetch the &amp;ldquo;Service Connector&amp;rdquo;, that connects to UPS to send the messages.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s fire up a browser and open the &lt;em&gt;Push Console App&lt;/em&gt; to create a couple of categories for instance: Football, Rugby and Basketball:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/8.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/8.png&#34; alt=&#34;8&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now go to your &lt;em&gt;Push Notifications Mobile Client&lt;/em&gt; and open the file called &lt;code&gt;push-config.json&lt;/code&gt;. You&amp;rsquo;ll need to update the &lt;em&gt;Variant ID&lt;/em&gt; and &lt;em&gt;Variant Secret&lt;/em&gt; for each platform and the &lt;em&gt;pushServerURL&lt;/em&gt; to the location of your UnifiedPush Server, so that it can register itself with the UnifiedPush Server in order to receive messages. For Android you also need to specify the &lt;em&gt;senderID&lt;/em&gt; (also called project number on the google console) inside of that JSON file. Finally build and install the &lt;em&gt;Push Notifications Mobile Client&lt;/em&gt; on a device and select the categories you want to receive.&lt;/p&gt;

&lt;p&gt;Now go back to the &lt;em&gt;Push Console App&lt;/em&gt; and send a message. If all worked well, you will see how the push notifications arrive on the mobile client.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/9.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/05/9.png&#34; alt=&#34;9&#34; /&gt;&lt;/a&gt;
You can use and extend this template for your own use case. More detailed information on the setup of this template can be found in the help of the App Console&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evolving a Mobile-centric Architecture: The Microservices Way</title>
      <link>http://feedhenrydevblogarchive.github.io/microservices-for-mobile/</link>
      <pubDate>Wed, 08 Apr 2015 13:54:34 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/microservices-for-mobile/</guid>
      <description>

&lt;p&gt;There seems to have been an explosion in the use of the term “microservices” recently. I’ve been peripherally aware of the concept for some time now, but it seems it first came to light with a fantastic collection of &lt;a href=&#34;http://martinfowler.com/articles/microservices.html&#34;&gt;thoughts by Martin Fowler&lt;/a&gt;[1] - some great reading on the topic.&lt;/p&gt;

&lt;p&gt;This three-part post will not help you make a business case for rewriting your existing monolith as a series of microservices - for that, I’d recommend &lt;a href=&#34;http://blog.softwhere.org/2015/02/21/microservices-the-new-architecture-for-digital-engagement/&#34;&gt;Rich Sharples’ writings on the topic&lt;/a&gt; [2] - but I am going to show how microservices make sense for mobile in a series of practical examples.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;A Microservices Primer: Introducing the concepts, along with mobile-specific microservice considerations&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hands-on examples how to build some simple microservices&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A benchmarking exercise revealing the impact microservices-based architectures can have on mobile.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The end result of this exercise can be performance improvements between ~**2.5x &lt;strong&gt;and&lt;/strong&gt; ~250x**, depending on network conditions[3]. To see a 10 minute video presentation &lt;a href=&#34;http://www2.feedhenry.com/mobile-tech-talk-microservices&#34;&gt;click here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-a-microservices-primer&#34;&gt;1: A Microservices Primer&lt;/h1&gt;

&lt;h2 id=&#34;microservices-the-term&#34;&gt;Microservices - The Term&lt;/h2&gt;

&lt;p&gt;I’ve been somewhat amused by the term microservices, since we&amp;rsquo;ve been composing small, loosely coupled applications which combine to do work since I first started using Node.js with FeedHenry. I&amp;rsquo;d love to claim some visionary stroke of trend-predicting genius, but really it’s the path the Node.js community led us down. Of course, it&amp;rsquo;s widely accepted the concept has been around since Unix days - it&amp;rsquo;s just a shiny new name.&lt;/p&gt;

&lt;p&gt;In the Node community, what started as cries of “Make everything you possibly can as small re-usable modules” (micromodules anybody?) quickly became &amp;ldquo;Make everything small re-usable applications,” and now we&amp;rsquo;re calling them microservices.&lt;/p&gt;

&lt;h2 id=&#34;microservices-considerations-for-mobile&#34;&gt;Microservices - Considerations for Mobile&lt;/h2&gt;

&lt;p&gt;Introducing a microservices-based architecture has some specific considerations when it comes to delivering content to mobile applications. I&amp;rsquo;m going to deal with two main concerns - &lt;strong&gt;coupling and performance&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;loose-coupled-tight-coupled-practically-welded-shut&#34;&gt;Loose-Coupled, Tight-Coupled, Practically Welded Shut&lt;/h3&gt;

&lt;p&gt;For web applications, if we change the API we know that once we deploy an update to the web application, all our connected clients are using the new API. It&amp;rsquo;s easy to swap out URLs, and even expected payloads in the code of the web application, because we can deploy in tandem. Then we can deprecate the old API. This makes for a relatively loose coupling between client and server.&lt;/p&gt;

&lt;p&gt;Mobile applications are different, however. A mobile app is released into an app store. In an enterprise environment, this app store is often private. We can usually force an update out to our app and watch it propagate to users within a matter of days. This makes the relationship between client and API more tightly coupled than in the case of the web application.&lt;/p&gt;

&lt;p&gt;Releasing to the public app store, there may be a review period, but once released, users download this update over the course of weeks, months, maybe never. The previous API still needs to be maintained, and this makes for an integration which is so tightly coupled, it&amp;rsquo;s practically welded shut. (See, these days everybody is coining new terms!)&lt;/p&gt;

&lt;p&gt;This makes for some very special considerations when architecting for mobile. The lifespan of any APIs the mobile application touches need to be much longer-lived, and APIs should be built with this in mind. Consider versioning, and some way of forcing users to update.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/Microservices_diag1.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/Microservices_diag1.png&#34; alt=&#34;Microservices_diag1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Mobile release cycles are much longer, leading to tighter coupling between client and API&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;performance-considerations&#34;&gt;Performance Considerations&lt;/h3&gt;

&lt;p&gt;The other major consideration specific to mobile is performance. Web applications typically run on devices connected over WiFi or Ethernet, with low latency. Mobile devices often connect over lossy connections - 3G, Edge, or even GPRS.&lt;/p&gt;

&lt;p&gt;Returning the minimum payload required to render the screen is more important now than ever. Intelligent pagination on lists can drastically reduce payload size, especially when users are only operating on the most recent items. This also means reducing the number of calls made across the network. As the number of calls grow, every HTTP transaction can contribute to an exponential growth in overall response time. Creating a microservice to act as a unified mobile API, which returns data from many sources in one single call is often a good option.&lt;/p&gt;

&lt;p&gt;This can introduce some interesting trade-offs that need to be balanced:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;At what point does a unified API returning multiple types of data compromise the RESTful nature of an API?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;At what point does the response body size of a combined payload negate any potential performance gains?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;2-a-mobile-example-of-a-microservice&#34;&gt;2. A Mobile Example of a Microservice&lt;/h1&gt;

&lt;p&gt;In part 1, we introduced the term, and presented some unique considerations for mobile. Now, let&amp;rsquo;s take a more practical look by creating some microservices.&lt;/p&gt;

&lt;h3 id=&#34;the-tale-of-the-traveling-umbrella-salesperson&#34;&gt;The Tale of the Traveling Umbrella Salesperson&lt;/h3&gt;

&lt;p&gt;To illustrate the use of microservices, let&amp;rsquo;s take a mock use case, that of a traveling umbrella salesperson (of no relation to the Traveling Salesperson of Distributed Computing fame). This salesperson needs to be able to:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create orders in a back-end database&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Automatically scale their order quantities according to the weather (I know - work with me here, people…)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Notify the account manager of the new order on their account&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;our-first-microservice-orders&#34;&gt;Our first Microservice - Orders&lt;/h3&gt;

&lt;p&gt;First, we&amp;rsquo;re going to create a microservice for orders for our traveling umbrella sales team. We&amp;rsquo;re going to write our microservices in Node.js, and they&amp;rsquo;re going to communicate JSON payloads over HTTP, but these are by no means prerequisites. Microservices can of course be implemented using any programming language, over any communication protocol.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a service which can both create and list umbrella orders. It creates a REST API, &lt;code&gt;/orders&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var app = require(&#39;express&#39;)().use(require(&#39;body-parser&#39;)());
var orders = [];
// Create a new order
app.post(&#39;/orders&#39;, function(req, res){
  orders.push(req.body);
  return res.json(req.body);
});
// list orders
app.get(&#39;/orders&#39;, function(req, res){
  return res.json(orders);
});

var server = app.listen(3000);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ten lines - pretty micro, huh? Ok, so I cheated a bit - that first line is concise to the point of unreadable, and we&amp;rsquo;re just putting orders in memory - but we now have a really micro service.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For future code snippets, I&amp;rsquo;m going to drop some of the boilerplate setup code on the first and last lines&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;adding-more-microservices-weather-and-sms&#34;&gt;Adding more Microservices - Weather and SMS&lt;/h2&gt;

&lt;p&gt;Our order service is working just fine - our folk out in the field can create orders, and list the orders they&amp;rsquo;ve previously created. But before the team creates an order, they want the system to scale their order size based on the upcoming weather forecast at that location. Let&amp;rsquo;s call this the rain service. Here, we&amp;rsquo;re going to reach out to a third party API, sum the rainfall totals for the upcoming forecast, and append it to the original weather information.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var weatherUrl = &#39;http://api.openweathermap.org/data/2.5/forecast&#39;;

app.get(&#39;/rain&#39;, function(req, res){
  var city = req.query.city,
  country = req.query.country;

  request.get({url : weatherUrl + &#39;?q=&#39; + city + &#39;,&#39; + country, json : true}, function(err, response, weatherbody){
    // sum all the inches rainfall in the forecast
    weatherbody.rainfall = _.reduce(weatherbody.list, function(a, b){ return a + b.rain[&#39;3h&#39;] }, 0);
    return res.json(weatherbody);
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lastly, we&amp;rsquo;re also going to add a service to allow us to push an SMS alert to the account manager when a new order is created.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app.post(&#39;/sms&#39;, function(req, res){
  var to = req.body.to,
  message = req.body.message;
  client.sms.messages.create({ to: to, from : process.env.TWILIO_NUM, body : message}, function(error, message){
    return res.json(message);
  });
});
app.listen(3002);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ve now created our series of three microservices. To get started with the examples provided, follow these steps in a terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# clone the repository
git clone https://github.com/cianclarke/microservices-primer.gitcd microservices-primer
# Install dependencies
npm install -d
# Set Twilio environment variables
export TWILIO_AUTH=foo; export TWILIO_SID=bar; export TWILIO_NUM=&amp;quot;+1234567&amp;quot;;
# start the 4 microservices &amp;amp; the test runner
npm start
# To view the test runner, visit http://localhost:3004/ in a browser. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re now running our series of microservices, and can interact with them using CURL&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Service 1: Create a new order in the database 
curl &#39;http://127.0.0.1:3000/orders/umbrellas&#39; -H &#39;Content-Type: application/json&#39; --data-binary &#39;{&amp;quot;city&amp;quot;:&amp;quot;Dublin&amp;quot;,&amp;quot;country&amp;quot;:&amp;quot;Ireland&amp;quot;,&amp;quot;quantity&amp;quot;:984.4999999999999,&amp;quot;accountManager&amp;quot;:&amp;quot;+1 123 456 789&amp;quot;}&#39; 
# Service 1: List orders in the database 
curl &#39;http://127.0.0.1:3000/orders/umbrellas&#39;
# Service 2: GET request to rain svc to retrieve info for Dublin 
curl &#39;http://127.0.0.1:3001/rain?city=Dublin&amp;amp;country=Ireland&#39; 
# Service 3: POST to the SMS service 
curl &#39;http://127.0.0.1:3002/sms&#39; -H &#39;Content-Type: application/json&#39; --data-binary &#39;{&amp;quot;to&amp;quot;:&amp;quot;+1 123 456 789&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;My SMS Message!&amp;quot;}&#39; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ve now built a series of microservices, and verified we can interact with them.3: Taking our Microservices MobileNow, let&amp;rsquo;s look at two different approaches to consuming these. The first will show a more traditional approach to building out the application. The second will introduce another microservice specifically for mobile, taking into account the mobile-specific concerns raised in part 1. Then, we&amp;rsquo;ll look at some results of our benchmark.&lt;/p&gt;

&lt;h2 id=&#34;take-1-client-side-business-logic&#34;&gt;Take 1: Client-Side Business Logic&lt;/h2&gt;

&lt;p&gt;First, we&amp;rsquo;ll build this application the way many existing mobile apps are built - we&amp;rsquo;ll implement a lot of business logic on the client (scaling the order according to the rainfall microservice, submitting to the orders microservice, then notifying the account manager via the SMS microservice), and make three separate REST calls from the mobile device.Sure, we&amp;rsquo;ve still got microservices on the server-side - but we could equally picture this as a monolith, for what little use we&amp;rsquo;re making of the microservices philosophy.&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/microservices_2.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/microservices_2.png&#34; alt=&#34;microservices_2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This illustrates the &amp;ldquo;wrong way.&amp;rdquo;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We’re making several calls from the app, so we’re not minimizing our number of requests.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;None of the calls have been optimized for mobile. We’re sending back unnecessary data, so we’re not trimming the payload for mobile.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;take-2-microservices-for-mobile&#34;&gt;Take 2: Microservices for Mobile&lt;/h2&gt;

&lt;p&gt;As before, we&amp;rsquo;re going to achieve this integration using a series of microservices - but we&amp;rsquo;re going to meld the data together in a fourth and final mobile-specific microservice.&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/microservices-3.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/microservices-3.png&#34; alt=&#34;microservices-3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now, we send our order information to a new mobile specific microservice which wraps up the three steps we took in “take 1.” We’re now making one call from the mobile device. We&amp;rsquo;ve got one simple API to maintain, a perfectly reasonable POST of a JSON payload, and this integration becomes a much looser coupling. We&amp;rsquo;re not sending unnecessary data back to the mobile app.&lt;/p&gt;

&lt;h2 id=&#34;benchmarking-client-side-logic-vs-microservices-approach-across-mobile-networks&#34;&gt;Benchmarking – Client-side Logic vs. Microservices approach across mobile networks&lt;/h2&gt;

&lt;p&gt;Now, let&amp;rsquo;s see how these two approaches compare across a range of mobile network types. If interested, some notes on the benchmarks are available in the footnotes[3].&lt;/p&gt;

&lt;p&gt;A simple mobile client implementing the two approaches to integrating discussed above was created, which also measures request time across each approach.&lt;/p&gt;

&lt;h3 id=&#34;payload-size&#34;&gt;Payload Size&lt;/h3&gt;

&lt;p&gt;First, a brief look at the total payload size over 100 requests. Using the mobile microservice, &lt;strong&gt;68kb&lt;/strong&gt; of data was exchanged. Calling each microservice individually resulted in &lt;strong&gt;1.5mb&lt;/strong&gt; of data, a substantial increase likely due to returning weather information in it&amp;rsquo;s entirety on every request.&lt;/p&gt;

&lt;h3 id=&#34;response-times&#34;&gt;Response Times&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/responseTimes.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2015/04/responseTimes.png&#34; alt=&#34;Response Times&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Examining the results, we see nominal difference between approaches using a 4G network. When we move to a 3G network, the gap widens - there&amp;rsquo;s eight** seconds** in the difference across requests. Edge networks show a wider gap still, with an increase in average request time of almost &lt;strong&gt;27 seconds&lt;/strong&gt;. At this point, the end user would really feel the pain of an inferior architecture. Lastly, over GPRS the impact of implementing multiple calls on the client is eye-opening. With average request times of &lt;strong&gt;more than 2&lt;/strong&gt;** minutes**, the application would be effectively unusable. Compare this to a microservice based architecture, with response times averaging 12 seconds, the application is slow but still usable. The key take away from this benchmark is that as the network slows, &lt;strong&gt;response times grow exponentially&lt;/strong&gt; when not considering mobile in your microservice architecture.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Having seen the results, what can we conclude from these benchmarks? I&amp;rsquo;m not going to try make such bold, linkbait-esque claims as &amp;ldquo;Microservices make mobile 10x faster&amp;rdquo; - that&amp;rsquo;s simply not true. What is true, however, is that the roll-out of a Microservices based architecture needs to consider mobile as a first class citizen. Not doing so can ruin the user experience for end users, and render applications virtually useless on slower networks. If the above considerations are taken into approach, the rollout of this new breed of architecture should prove a much smoother transition.&lt;/p&gt;

&lt;h1 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h1&gt;

&lt;p&gt;[1] Martin Fowler - Microservices. The post which for many started the momentum behind the term.
&lt;a href=&#34;http://martinfowler.com/articles/microservices.html&#34;&gt;http://martinfowler.com/articles/microservices.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] Rich Sharples - Micro services – the new architecture for digital engagement? Some observations from a higher level on the trends and applications of microservices.
&lt;a href=&#34;http://blog.softwhere.org/2015/02/21/microservices-the-new-architecture-for-digital-engagement/&#34;&gt;http://blog.softwhere.org/2015/02/21/microservices-the-new-architecture-for-digital-engagement/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] 100 requests in each run. SMS API calls to Twilio simulated with 250ms timeout to avoid excessive calls to their API. Chrome Developer Tools network throttling used to simulate network speeds. Node.js processes restarted after every batch of 100 requests. Requests had timestamp appended to prevent browser caching.&lt;/p&gt;

&lt;p&gt;Watch a powerful &lt;a href=&#34;http://www2.feedhenry.com/mobile-tech-talk-microservices&#34;&gt;10-minute video&lt;/a&gt; on this content that includes a live demo of the benchmarking exercise.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.twitter.com/cianclarke&#34;&gt;@cianclarke&lt;/a&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/06/Screen-Shot-2014-06-11-at-15.56.07.png&#34;&gt; &lt;/a&gt;is a Software Engineer with FeedHenry. Primarily focused on the mobile-backend-as-a-service space, Cian is responsible for many of FeedHenry’s mBaaS developer features.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;*[mBaaS]: Mobile Backend As A Service&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Web Scraping for Fun &amp; Profit II</title>
      <link>http://feedhenrydevblogarchive.github.io/web-scraping-for-fun-profit-ii/</link>
      <pubDate>Mon, 08 Dec 2014 15:36:19 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/web-scraping-for-fun-profit-ii/</guid>
      <description>

&lt;p&gt;In my &lt;a href=&#34;http://www.feedhenry.com/web-scraping-fun-profit/&#34;&gt;Web Scraping blog post&lt;/a&gt;, I described some simple ways to retrieve data from a web page using Node.js. This means of data retrieval proves useful when no API is available.
Today, I&amp;rsquo;m going to describe similar techniques where reverse engineering &amp;amp; more complex authentication flows are involved to retrieve data.&lt;/p&gt;

&lt;h2 id=&#34;authentication&#34;&gt;Authentication&lt;/h2&gt;

&lt;p&gt;When we need to authenticate before viewing the data we need to scrape, the complexity increases significantly. There&amp;rsquo;s many different types of authentication - the vast majority of which we can tackle in Node.js.&lt;/p&gt;

&lt;p&gt;When an authentication API absolutely can&amp;rsquo;t be exposed, for whatever reason, my next point of call is to the web version of the login. We&amp;rsquo;re going to reverse engineer the login flow of my demo FeedHenry platform instance, and doing this requires as much information about the login flow as possible.
First, it&amp;rsquo;s over to the web browser to see how things work on the website. Using the Google Chrome inspector, and turning on recording of requests across page loads, we can see how the login flow works. Note I&amp;rsquo;ve also ticked the &amp;lsquo;Preserve Log&amp;rsquo; option.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-01-at-16.14.27.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-01-at-16.14.27-300x99.png&#34; alt=&#34;Screen Shot 2014-12-01 at 16.14.27&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After a login request has been sent, we can inspect the request body, and find the information we need to reconstruct this request in Node.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/login2.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/login2-300x243.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L8&#34;&gt;Request URL&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L9&#34;&gt;Request Method&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We note the response headers contains a cookie which enables us to authenticate future requests&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We take note of the content type - in this case, &lt;code&gt;application/json&lt;/code&gt; data. (Passing&lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L11-L14&#34;&gt; a &amp;lsquo;json&amp;rsquo; property&lt;/a&gt; to request automatically gives us this content type).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L11-L14&#34;&gt;We see the JSON payload being transmitted. &lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is a pretty simple example, but sometimes more advanced params are required. A good way to debug is right click on the request in the inspector tab (highlighted in blue above), and click &amp;ldquo;Copy as cURL&amp;rdquo;. This will copy a cURL command to your clipboard which you can run in a terminal window. Start dropping headers and other pieces of information that look unimportant until you&amp;rsquo;re left with a bare-bones working request.&lt;/p&gt;

&lt;p&gt;From gathering this info in the chrome inspector, we can construct a &lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js&#34;&gt;request in Node replicating this login flow&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var request = require(&#39;request&#39;),
jsdom = require(&#39;jsdom&#39;),
jar = request.jar(), // stores cookies in the &amp;quot;jar&amp;quot;, we can re-use them in future authenticated requests

// A closure function to enclose our code within
(function(username, password){
  request.post({
    url : &#39;https://testing.feedhenry.me/box/srv/1.1/act/sys/auth/login&#39;,
    method : &#39;post&#39;,
    jar : jar,
    json : {
      u : username,
      p : password,
      d : &amp;quot;testing&amp;quot;
    },
  }, function(err, res, body){
    if (err){
      console.error(err);
      return;
    }

    // We&#39;re in - we can now do subsequent, authenticated requests within the website by just including the same cookie jar, like so:

    request.get({
      url : &#39;https://testing.feedhenry.me/box/api/projects&#39;,
      jar : jar,
      json : true
    }, function(err, res, body){
      console.log(&#39;Got &#39; + body.length + &#39; projects&#39;);
    });

  });
})(&amp;quot;blog@demo.com&amp;quot;, &amp;quot;Blogpost123&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we succeed, because our login information is stored in the shared &amp;ldquo;Cookie Jar&amp;rdquo; &lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L3&#34;&gt;we constructed at the start&lt;/a&gt;, we can now make authenticated requests to &lt;a href=&#34;https://gist.github.com/cianclarke/beb3ee79e0ebfed62f0b#file-feedhenrylogin-js-L23-L30&#34;&gt;other parts of the system&lt;/a&gt;.
This is a very simple way of performing a login flow.&lt;/p&gt;

&lt;h2 id=&#34;interval-based-scraping-cron-cache&#34;&gt;Interval-based Scraping: Cron &amp;amp; Cache&lt;/h2&gt;

&lt;p&gt;Sometimes, we want to be able to reduce the time it takes for our scraper to run. Usually, we&amp;rsquo;ll do this on an interval by caching the data.&lt;/p&gt;

&lt;p&gt;To do this, we&amp;rsquo;ll &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L10&#34;&gt;extract our previous scraper code into a function&lt;/a&gt;. Then, we&amp;rsquo;ll modify our previous scraper - instead of &lt;code&gt;console.log&lt;/code&gt;-ing the number of projects, we&amp;rsquo;ll &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L33&#34;&gt;put them into a simple in-memory cache&lt;/a&gt; using the &lt;a href=&#34;https://github.com/ptarjan/node-cache&#34;&gt;memory-cache module&lt;/a&gt;.
Now, we &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L39&#34;&gt;call our scraper function once&lt;/a&gt; to prime the cache, and &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L40-L42&#34;&gt;set up an interval&lt;/a&gt; (every &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L8&#34;&gt;15 mins&lt;/a&gt; in this case) to refresh the cache.
Lastly, we use a &lt;a href=&#34;https://gist.github.com/cianclarke/4e78314aafcc1b41ca44#file-polling-js-L46-L50&#34;&gt;simple web server to respond with the cached data&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This could easily be expanded using the fantastic &lt;a href=&#34;https://github.com/ncb000gt/node-cron&#34;&gt;&lt;code&gt;node-cron&lt;/code&gt; module &lt;/a&gt;to allow us to set up more advanced schedules in a unix crontab fashion. It&amp;rsquo;d also be advisable to use Redis for caching this data over an in-memory cache - just use &lt;a href=&#34;http://docs.feedhenry.com/v3/api/api_cache.html&#34;&gt;$fh.cache&lt;/a&gt; in FeedHenry.&lt;/p&gt;

&lt;h2 id=&#34;other-popular-authentication-mechanisms&#34;&gt;Other Popular Authentication Mechanisms&lt;/h2&gt;

&lt;p&gt;A myriad of authentication mechanisms exist- often much more advanced use cases. I&amp;rsquo;ve attempted to cover some here, with a worked example.&lt;/p&gt;

&lt;h3 id=&#34;form-data&#34;&gt;&lt;strong&gt;Form Data&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;We can identify Form Data in the browser by looking for the request content-type &lt;code&gt;application/x-www-form-urlencoded&lt;/code&gt;, along with a Form Data section in the request inspector of the browser:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-01-at-16.39.00.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-01-at-16.39.00-300x62.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Node.js makes Form Data really simple. It can be appended to the request by replacing our &lt;a href=&#34;https://gist.github.com/cianclarke/21aacdd06f22d33e663c#file-gistfile1-js-L10-L14&#34;&gt;&lt;code&gt;json&lt;/code&gt; option with &lt;code&gt;form&lt;/code&gt;.&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;csrf-tokens&#34;&gt;&lt;strong&gt;CSRF Tokens&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Some sites will require a &lt;a href=&#34;http://en.wikipedia.org/wiki/Cross-site_request_forgery&#34;&gt;CSRF (Cross Site Request Forgery)&lt;/a&gt; token from the login page before even performing the login request. This token is usually a hidden input on the page. If we can identify the CSRF token in the browser, we can then search the HTML source of the page for it.
To overcome these tokens in node.js code, we can first load the login page using a &lt;code&gt;GET&lt;/code&gt; request, and then use JSDom to pick out the CSRF token.&lt;/p&gt;

&lt;h3 id=&#34;redirects&#34;&gt;&lt;strong&gt;Redirects&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Another popular flow is many redirects before reaching final destination - &lt;a href=&#34;https://github.com/mikeal/request#requestoptions-callback&#34;&gt;the &amp;lsquo;followAllRedirects&amp;rsquo; option of request&lt;/a&gt; is useful when this is required.&lt;/p&gt;

&lt;h3 id=&#34;an-example-openshift-online&#34;&gt;An Example - OpenShift Online&lt;/h3&gt;

&lt;p&gt;The login form for OpenShift Online illustrates these concepts perfectly - namely:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;A CSRF-like token &lt;a href=&#34;https://gist.github.com/cianclarke/54d58cad0c3a9cbecdd5#file-gistfile1-txt-L17&#34;&gt;pulled from the page using JSDom&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cianclarke/54d58cad0c3a9cbecdd5#file-gistfile1-txt-L24-L30&#34;&gt;Form data&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/cianclarke/54d58cad0c3a9cbecdd5#file-gistfile1-txt-L9&#34;&gt;The need to follow through redirects&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;var request = require(&amp;lsquo;request&amp;rsquo;),
jsdom = require(&amp;lsquo;jsdom&amp;rsquo;),
jar = request.jar(); // stores cookies in the &amp;ldquo;jar&amp;rdquo;, we can re-use them in future authenticated requests&lt;/p&gt;

&lt;p&gt;request({
  url : &amp;lsquo;&lt;a href=&#34;https://openshift.redhat.com/app/login&#39;&#34;&gt;https://openshift.redhat.com/app/login&#39;&lt;/a&gt;,
  method : &amp;lsquo;get&amp;rsquo;,
  jar : jar,
  followAllRedirects : true
}, function(err, response, body){
  if (err){
    console.error(err);
    return;
  }
  jsdom.env(body,[&amp;ldquo;&lt;a href=&#34;http://code.jquery.com/jquery.js&amp;quot;&#34;&gt;http://code.jquery.com/jquery.js&amp;quot;&lt;/a&gt;], function (errors, window) {
    var $ = window.$,
    token = $(&amp;lsquo;input[name=authenticity_token]&amp;lsquo;).val(),
    utf8 = $(&amp;lsquo;input[name=utf8]&amp;lsquo;).val();
    request.post({
      url : &amp;lsquo;&lt;a href=&#34;https://openshift.redhat.com/app/login&#39;&#34;&gt;https://openshift.redhat.com/app/login&#39;&lt;/a&gt;,
      method : &amp;lsquo;post&amp;rsquo;,
      jar : jar,
      followAllRedirects : true,
      form : {
        &amp;ldquo;web_user[rhlogin]&amp;rdquo; : &amp;ldquo;foo@bar.com&amp;rdquo;,
        &amp;ldquo;web_user[password]&amp;rdquo; : &amp;ldquo;foobar&amp;rdquo;,
        &amp;ldquo;commit&amp;rdquo; : &amp;ldquo;Sign in&amp;rdquo;,
        &amp;ldquo;authenticity_token&amp;rdquo; : token,
        &amp;ldquo;utf8&amp;rdquo; : utf8
      }
    }, function(err, res, body){
      if (body.indexOf(&amp;lsquo;My Account&amp;rsquo;)&amp;gt;-1){
        console.log(&amp;lsquo;We\&amp;rsquo;re in, and have headers in the jar to allow us to do authenticated requests!&amp;lsquo;);
      }
    });
  });
});&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;token-based-authentication&#34;&gt;&lt;strong&gt;Token based Authentication&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Many authentication systems can perform authentication flows where a username and password is passed to the backend, and it returns an authentication token which is appended to future request bodies. This is common with SOAP based services, but can exist in JSON APIs too. How these work are best investigated using the network tab of the inspector, then mimicking the flow in code.&lt;/p&gt;

&lt;h3 id=&#34;debugging-with-a-proxy&#34;&gt;&lt;strong&gt;Debugging with a Proxy&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-05-at-09.58.33.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/12/Screen-Shot-2014-12-05-at-09.58.33-300x196.png&#34; alt=&#34;Using Charles Proxy&#34; /&gt;&lt;/a&gt;If we&amp;rsquo;re trying to replicate the login flow of a mobile app, command line utility, or software tool that doesn&amp;rsquo;t live in a browser, I often use the Charles debugging proxy to inspect the data flow just like we did with the browser above. To use this, your target needs to support a HTTP proxy. Most command line utilities and software packages do, and to set it up with a mobile phone, just use the system proxy. &lt;a href=&#34;http://cianclarke.com/blog/how-popular-apps-access-apis/&#34;&gt;See my previous post on this&lt;/a&gt; for more details on using a debugging proxy.
It&amp;rsquo;s also beneficial to be able to track the progress of requests through a Node.js application - you can use the charles proxy when using request like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;request.get({
  url : &#39;http://www.google.ie&#39;,
  proxy : &#39;http://127.0.0.1:8080&#39;
}, function(error, response, body){ 
  // This request has now flown through the Charles proxy
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;further-reading-tools&#34;&gt;Further Reading &amp;amp; Tools&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.feedhenry.com/web-scraping-fun-profit/&#34;&gt;Web Scraping for Fun &amp;amp; Profit I&lt;/a&gt; - Precursor to this post&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/tmpvar/jsdom&#34;&gt;JSDom&lt;/a&gt; - Run jQuery DOM queries (&amp;amp; others) on a web page from ServerSide&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://phantomjs.org/&#34;&gt;PhantomJS&lt;/a&gt; - Headless browser &amp;amp; JavaScript API&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.charlesproxy.com/&#34;&gt;Charles&lt;/a&gt; -  Debugging Proxy&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://casperjs.org/&#34;&gt;CasperJS&lt;/a&gt; - Testing utility which could also be used to build advanced scraping utilities&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A walkthrough of our new Teams &amp; Collaboration functionality</title>
      <link>http://feedhenrydevblogarchive.github.io/a-walkthrough-of-our-new-teams-collaboration-functionality/</link>
      <pubDate>Wed, 19 Nov 2014 17:03:47 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/a-walkthrough-of-our-new-teams-collaboration-functionality/</guid>
      <description>&lt;p&gt;Today &lt;a href=&#34;http://www.feedhenry.com/red-hat-new-teams-and-collaboration-enhancement-feedhenry/&#34;&gt;we announced&lt;/a&gt; our new Teams &amp;amp; Collaboration feature-set which enables both technical and non-technical teams to work together on complex enterprise mobility projects in both a collaborative and controlled way.&lt;/p&gt;

&lt;p&gt;FeedHenry 3 projects often have native Android and iOS teams, a Hybrid team, a web-app team, a Node.js team and Enterprise connector teams before you even consider outsourcers, configuration managers and data processors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/11/teams_collabs.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/11/teams_collabs.jpg&#34; alt=&#34;teams_collabs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Teams &amp;amp; Collaboration is built on several simple but powerful concepts so that complex teams, organisations and projects such as these can be setup. You get fine-grained control over every component in the platform so that the right people have the right access to the right things and nothing else.&lt;/p&gt;

&lt;p&gt;In the video below, I walk through all the details including an end-to-end setup for an example iOS Development team so you can really get a feeling for how powerful this functionality is.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FeedHenry and Red Hat Pushing ahead with Integrations</title>
      <link>http://feedhenrydevblogarchive.github.io/feedhenry-and-red-hat-pushing-ahead-with-integrations/</link>
      <pubDate>Mon, 10 Nov 2014 16:41:47 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/feedhenry-and-red-hat-pushing-ahead-with-integrations/</guid>
      <description>

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;It&amp;rsquo;s been only 4 weeks since Red Hat acquired FeedHenry and we are delighted to be able to already announce the immediate availability of the first FeedHenry MBaaS Service for integrating with the Red Hat product suite. AeroGear - Red Hat&amp;rsquo;s open source offering for Unified Push Notification - can now be seamlessly accessed and leveraged as a microservice from the FeedHenry MBaaS Service Catalog. The driver for this integration is the upcoming &lt;a href=&#34;http://www.devoxx.be/&#34;&gt;Devoxx conference&lt;/a&gt;, where we will be showcasing the FeedHenry Mobile application Platform integrating with a range of Red Hat products and service in a fun and interactive demo as part of &lt;a href=&#34;http://www.devoxx.be/keynotes-2014&#34;&gt;Wednesday&amp;rsquo;s Keynote&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;aero-gear&#34;&gt;Aero Gear&lt;/h1&gt;

&lt;p&gt;The &lt;a href=&#34;http://aerogear.org/&#34;&gt;AeroGear&lt;/a&gt; project is a one stop solution for all your Push Notification needs - covering Native iOS &amp;amp; Android, Cordova Hybrid as well as Simple Push for Web. It is available to use right now from the &lt;a href=&#34;https://marketplace.openshift.com/apps/9907#!overview&#34;&gt;OpenShift Marketplace&lt;/a&gt; - so feel free to give it a whirl.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/11/AeroGear-on-OpenShift.png&#34; alt=&#34;AeroGear on OpenShift&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;mbaas-integration&#34;&gt;MBaaS Integration&lt;/h1&gt;

&lt;p&gt;The new AeroGear MBaaS Integration Services leverages the excellent &lt;a href=&#34;https://www.npmjs.org/package/aerogear-sender-client&#34;&gt;Node.js module&lt;/a&gt; already developed by the AeroGear team and provides a simple, secure way to integrate Push Notifications into your FeedHenry apps. As you would expect, it uses all the out of the box functionality offered by FeedHenry MBaaS services such as interactive API documentation, wizard based configuration and a fine grained security model. The service itself is quick and painless to set up - simply provide the details of your AeroGear installation and credentials for the AeroGear app you want to use and you are ready to go. Using the service is just as easy - as a standard FeedHenry MBaaS service, you can call it in exactly the same way as you would any other MBaaS service - with a clean, crisp FeedHenry API call. For more information on FeedHenry MBaaS Services, check out &lt;a href=&#34;http://vimeo.com/98683877&#34;&gt;this video&lt;/a&gt; or &lt;a href=&#34;http://www.feedhenry.com/contact/&#34;&gt;send us a message&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/11/AeroGear-MBaaS-Service.png&#34; alt=&#34;AeroGear MBaaS Service&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;This is a great first step in integration with the superb Red Hat product suite and is just a taster of things to come. Stay tuned for more MBaaS integrations to Red Hat product in the coming months and don&amp;rsquo;t forget to checkout the &lt;a href=&#34;http://www.devoxx.be/&#34;&gt;Devoxx website&lt;/a&gt; for lots more information on what&amp;rsquo;s coming up at this excellent conference.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publishing the gitlab-shell Java client to the Maven Central Repository</title>
      <link>http://feedhenrydevblogarchive.github.io/publishing-jar-maven-central-repository/</link>
      <pubDate>Sat, 18 Oct 2014 10:08:51 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/publishing-jar-maven-central-repository/</guid>
      <description>

&lt;h1 id=&#34;what-library-is-being-published-and-why&#34;&gt;What library is being published, and why?&lt;/h1&gt;

&lt;p&gt;The library being published to maven is a java client for interacting remotely with gitlab-shell &lt;a href=&#34;https://github.com/gitlabhq/gitlab-shell&#34;&gt;https://github.com/gitlabhq/gitlab-shell&lt;/a&gt;.
It uses the &lt;a href=&#34;http://www.jcraft.com/jsch/&#34;&gt;Jsch&lt;/a&gt; libary to remotely connect (SSH) to the machine with gitlab-shell installed, and execute gitlab-shell administration commands.&lt;/p&gt;

&lt;p&gt;The reason for creating this library is because one did not exist already. There are many different gitlab client libraries, but none for interacting directly with gitlab-shell, the underlying git repository service for gitlab.&lt;/p&gt;

&lt;h1 id=&#34;creating-a-new-gradle-project-in-eclipse&#34;&gt;Creating a new gradle project in Eclipse&lt;/h1&gt;

&lt;p&gt;To configure Eclipse for working with Gradle projects, the update site at &lt;a href=&#34;http://dist.springsource.com/release/TOOLS/gradle&#34;&gt;http://dist.springsource.com/release/TOOLS/gradle&lt;/a&gt; was added, and the &amp;lsquo;Gradle IDE&amp;rsquo; plugin installed.
Once installed, a new `Gradle Project&amp;rsquo; was created based off the &amp;lsquo;Java Quickstart&amp;rsquo; sample project.
The sample project includes the following files &amp;amp; directories by default:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;.classpath
.gradle/
.project
.settings/
bin/
build/
build.gradle
src/main/java/
src/main/resources/
src/test/java/
src/test/resources/
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The most important files &amp;amp; folders here are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;.classpath - projcect classpath with a sepcial entry for &amp;lsquo;gradle&amp;rsquo; (org.springsource.ide.eclipse.gradle.classpathcontainer)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;build.gradle - the gradle project build file. A right-click context menu called &amp;lsquo;Gradle&amp;rsquo; will give some useful tasks to run against your project&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;src/main/java - your java source files&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A sample &lt;code&gt;.gitignore&lt;/code&gt; file for what should &amp;amp; shouldn&amp;rsquo;t be checked into git can be found here &lt;a href=&#34;https://github.com/feedhenry/gitlab-shell-client/blob/master/.gitignore&#34;&gt;https://github.com/feedhenry/gitlab-shell-client/blob/master/.gitignore&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;writing-the-library&#34;&gt;Writing the library&lt;/h1&gt;

&lt;p&gt;Before starting to write the library, the sample contents in the src folders was removed.
The library is going to be quite simple as it has 2 primary tasks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;remotely connect to a machine over ssh&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;execute a command&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To perform the ssh connection, we&amp;rsquo;re using Jsch, a java implementation of the SSH client.
To allow importing it in our source code, we added the following dependency to build.gradle.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;dependencies {
    compile &#39;com.jcraft:jsch:0.1.51&#39;
}
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re focusing on creating and publishing an artifact to maven central in this article, so the library implementation details will be kept brief.
The client follows the Builder pattern, and allows adding, removing &amp;amp; listing both projects &amp;amp; keys.
The java source code for doing this can be found at &lt;a href=&#34;https://github.com/feedhenry/gitlab-shell-client/blob/master/src/main/java/com/feedhenry/gitlabshell/GLSClient.java&#34;&gt;https://github.com/feedhenry/gitlab-shell-client/blob/master/src/main/java/com/feedhenry/gitlabshell/GLSClient.java&lt;/a&gt;.
Usage instructions &amp;amp; sample code can be found in the README file &lt;a href=&#34;https://github.com/feedhenry/gitlab-shell-client&#34;&gt;https://github.com/feedhenry/gitlab-shell-client&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;publishing-the-library&#34;&gt;Publishing the library&lt;/h1&gt;

&lt;p&gt;Before the library can be published to maven central &lt;a href=&#34;http://search.maven.org/&#34;&gt;http://search.maven.org/&lt;/a&gt;, we have to publish it to the Sonatype OSS Nexus Repository, then &amp;lsquo;Release&amp;rsquo; it to the central maven repository.
This process is long-winded compared to other package manager repos, such as npm &lt;a href=&#34;https://www.npmjs.org/&#34;&gt;https://www.npmjs.org/&lt;/a&gt; for node.js pacakges, but becomes easier after the first publication.
For the most part, the guide at &lt;a href=&#34;http://central.sonatype.org/pages/ossrh-guide.html&#34;&gt;http://central.sonatype.org/pages/ossrh-guide.html&lt;/a&gt; was followed.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create a JIRA account at &lt;a href=&#34;https://issues.sonatype.org&#34;&gt;https://issues.sonatype.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a &amp;lsquo;New Project&amp;rsquo; ticket, giving details of the project such as the &amp;lsquo;Group ID&amp;rsquo; (we&amp;rsquo;re using com.feedhenry)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Wait for a reply, giving details of the repositories that can now be published to and downloaded from&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Publish the release artifact (using gradle) to the staging repository&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Promote the uploaded artifact from &amp;lsquo;Staged&amp;rsquo; to &amp;lsquo;Releases&amp;rsquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Comment back on the JIRA ticket, giving details for the promoted artifact, so that syncronisation of your artifacts to maven central is activated&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A example of this ticket process from start to finish can be seen at &lt;a href=&#34;https://issues.sonatype.org/browse/OSSRH-11591&#34;&gt;https://issues.sonatype.org/browse/OSSRH-11591&lt;/a&gt;.
Of all these steps, the hardest is the publishing, as it requires some important configuration before running the publish command.&lt;/p&gt;

&lt;p&gt;The first tricky step is configuring your &lt;code&gt;gradle.properties&lt;/code&gt; file in &lt;code&gt;~/.gradle/&lt;/code&gt;.
This file contains your username &amp;amp; password for &lt;a href=&#34;http://central.sonatype.org&#34;&gt;http://central.sonatype.org&lt;/a&gt;, and gpg key &amp;amp; password details for signing artifacts before uploading them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;signing.keyId=YourKeyId
signing.password=YourPublicKeyPassword
signing.secretKeyRingFile=PathToYourKeyRingFile

ossrhUsername=your-jira-id
ossrhPassword=your-jira-password
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The username &amp;amp; password are those from your created account above.
The guide at &lt;a href=&#34;http://central.sonatype.org/pages/working-with-pgp-signatures.html&#34;&gt;http://central.sonatype.org/pages/working-with-pgp-signatures.html&lt;/a&gt; was followed for setting up a gpg key.
A sample filled in properties file would be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;signing.keyId=171147D9
signing.password=password
signing.secretKeyRingFile=/Users/dmartin/.gnupg/secring.gpg

ossrhUsername=david.martin.fh
ossrhPassword=password
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The second tricky step is the build.gradle file.
There are a few important configuration blocks needed to tell gradle what we&amp;rsquo;re uploading and where to upload it to.
The guide at &lt;a href=&#34;http://central.sonatype.org/pages/gradle.html&#34;&gt;http://central.sonatype.org/pages/gradle.html&lt;/a&gt; was very useful in filling out these details.
A full working build.gradle file can be seen at &lt;a href=&#34;https://github.com/feedhenry/gitlab-shell-client/blob/master/build.gradle&#34;&gt;https://github.com/feedhenry/gitlab-shell-client/blob/master/build.gradle&lt;/a&gt;
The important blocks are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;// artifacts to upload i.e. built archive, javadoc &amp;amp; source code, all in jar format
artifacts {
  archives javadocJar, sourcesJar
}

// sign the content before uploading
signing {
  sign configurations.archives
}

// upload our artifacts to the staging repository mentioned in the JIRA ticket
uploadArchives {
  repositories {
    mavenDeployer {
      // ...

      repository(url: &amp;quot;https://oss.sonatype.org/service/local/staging/deploy/maven2/&amp;quot;) {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }
// ...
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once all of this is configured, the artifact can be published with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;gradle uploadArchives
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the upload was successful, the next step is to &amp;lsquo;promote&amp;rsquo; the artifact from staging to release.
The guide at &lt;a href=&#34;http://central.sonatype.org/pages/releasing-the-deployment.html&#34;&gt;http://central.sonatype.org/pages/releasing-the-deployment.html&lt;/a&gt; was followed for this step.
This step can be made easier by using the &amp;lsquo;Nexus Staging Maven Plugin&amp;rsquo;, but for now we used the website.&lt;/p&gt;

&lt;p&gt;Once done, a comment can be left on the JIRA ticket with details of the &amp;lsquo;released&amp;rsquo; artifact.
After some time, there should be a response indicating the maven central sync has been enabled (and may take some time to update)
If everything has gone to plan, you can search for your artifact e.g. &lt;a href=&#34;http://search.maven.org/#artifactdetails%7Ccom.feedhenry.gitlabshell%7Cgitlab-shell-client%7C1.0%7Cjar&#34;&gt;http://search.maven.org/#artifactdetails%7Ccom.feedhenry.gitlabshell%7Cgitlab-shell-client%7C1.0%7Cjar&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;using-the-libary-in-other-projects&#34;&gt;Using the libary in other projects&lt;/h1&gt;

&lt;p&gt;The artifact details page on maven central shows Dependency Information for various build tools.
Using the library is a matter of copying &amp;amp; pasting the sample code.
For example, to include our gitlab-shell-client module in a gradle project, we include the following in build.gradle:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;dependencies {
    compile &#39;com.feedhenry.gitlabshell:gitlab-shell-client:1.0&#39;
}
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, to use the artifact in a maven project, we include the following in our pom.xml:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.feedhenry.gitlabshell&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;gitlab-shell-client&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Creating &amp; Publishing a Chef Cookbook for gitlab-shell</title>
      <link>http://feedhenrydevblogarchive.github.io/gitlab-shell-chef-cookbook/</link>
      <pubDate>Sat, 11 Oct 2014 12:25:34 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/gitlab-shell-chef-cookbook/</guid>
      <description>

&lt;h1 id=&#34;what-was-done-and-why&#34;&gt;What was done and why?&lt;/h1&gt;

&lt;p&gt;This article details the steps that were followed to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create a new chef cookbook (for installing gitlab-shell)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Write a recipe, with a set of configurable attributes&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deploy/Publish this cookbook to the &amp;lsquo;Chef Supermarket&amp;rsquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Include the newly published cookbook in chef based project&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The main reason for doing this was because a cookbook for installing &lt;strong&gt;just&lt;/strong&gt; gitlab-shell did not exist (More than 1 for a full gitlab installation did)&lt;/p&gt;

&lt;h1 id=&#34;creating-the-cookbook&#34;&gt;Creating the cookbook&lt;/h1&gt;

&lt;p&gt;The &lt;code&gt;knife&lt;/code&gt; command is the main cli tool for doing chef stuff. For example, to create a new cookbook in the default cookbook location, do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;knife cookbook create &amp;lt;coobookname&amp;gt;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The default location is usually &lt;code&gt;~/.chef/cookbooks/&lt;/code&gt;. To specify a location, the &lt;code&gt;-o&lt;/code&gt; switch can be used e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;knife cookbook create gitlab-shell -o ~/work
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This creates a bunch of files &amp;amp; folders, a lot of which won&amp;rsquo;t be needed this time. Some files will have useful placeholder info, especially the README.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;-rw-r--r-- CHANGELOG.md
-rw-r--r-- README.md
drwxr-xr-x attributes
drwxr-xr-x definitions
drwxr-xr-x files
drwxr-xr-x libraries
-rw-r--r-- metadata.rb
drwxr-xr-x providers
drwxr-xr-x recipes
drwxr-xr-x resources
drwxr-xr-x templates
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main files &amp;amp; folders are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;metadata.rb - cookbook definition &amp;amp; version&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;README.md - cookbook details, usage and attributes/config information&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CHANGELOG.md - your cookbook changes for each version&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;/attributes - configuration files go in here&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;/recipes - installation &amp;amp; setup script(s)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;/files - files to &amp;lsquo;drop in&amp;rsquo; during installation and setup&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;/templates - files to &amp;lsquo;drop in&amp;rsquo; with placeholders replaced with config values&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;cookbook-recipe&#34;&gt;Cookbook recipe&lt;/h1&gt;

&lt;p&gt;This is a simple recipe, so we can do everything in a single file to install &amp;amp; setup gitlab-shell. This file is &lt;code&gt;recipes/default.rb&lt;/code&gt; To install gitlab-shell, there are a few steps&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create a new user called &lt;code&gt;git&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Clone the gitlab-shell repo from github&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a config.yml file using a chef template file&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ensure the gitlab repositories path is created and has the correct perms&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ensure the &lt;code&gt;git&lt;/code&gt; users authorized_keys file is created with the correct perms&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete source for this can be found at &lt;a href=&#34;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/recipes/default.rb&#34;&gt;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/recipes/default.rb&lt;/a&gt; The most interesting part of the recipe is the template file for config.yml. The template file is in templates/default/gitlab_shell.yml.erb &lt;a href=&#34;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/templates/default/gitlab_shell.yml.erb&#34;&gt;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/templates/default/gitlab_shell.yml.erb&lt;/a&gt; It&amp;rsquo;s an embedded ruby template file, so there are some ruby placeholders in it. For example, the url to call back to for checking repo access and key permissions is injected here:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;gitlab_url: &amp;lt;%= @url %&amp;gt;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Back in the recipe, the template file is output to the gitlab-shell install directory as config.yml. The code to do this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;template File.join(gitlab_shell[&#39;shell_path&#39;], &amp;quot;config.yml&amp;quot;) do
  source &amp;quot;gitlab_shell.yml.erb&amp;quot;
  user gitlab_shell[&#39;user&#39;]
  group gitlab_shell[&#39;group&#39;]
  variables({
    # ....
    :url =&amp;gt; gitlab_shell[&#39;url&#39;],
    # ....
  })
end
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The variables section is the object/hash passed into the template file. The value for this config is obtained from the cookbook attributes. More specifically, the file at attributes/default.rb &lt;a href=&#34;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/attributes/default.rb&#34;&gt;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/attributes/default.rb&lt;/a&gt; The &lt;code&gt;gitlab_url&lt;/code&gt; value comes from the following attribute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;default[&#39;gitlab-shell&#39;][&#39;url&#39;] = &amp;quot;http://localhost:3000/&amp;quot;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;cookbook-preparation-for-publish&#34;&gt;Cookbook preparation for publish&lt;/h1&gt;

&lt;p&gt;Now that we have a cookbook, we can publish it to the Chef Supermarked at &lt;a href=&#34;https://supermarket.getchef.com&#34;&gt;https://supermarket.getchef.com&lt;/a&gt;. To do this, we need an account. At the time of writing, and account can be created at &lt;a href=&#34;https://manage.opscode.com/signup?ref=community&#34;&gt;https://manage.opscode.com/signup?ref=community&lt;/a&gt;. After creating one and signing in, you&amp;rsquo;ll be prompted to download/save your newly generated private key. The suggested location is &lt;code&gt;~/.chef/&amp;lt;userid&amp;gt;.pem&lt;/code&gt;. This can be used later when we want to upload our cookbook from the terminal. Before uploading, we should make sure our README.md and metadata.rb files are in order.&lt;/p&gt;

&lt;h2 id=&#34;readme-md&#34;&gt;README.md&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/README.md&#34;&gt;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/README.md&lt;/a&gt; This file is whats shown to users browsing cookbooks in the Chef Supermarket. The suggested content, based on the generated file form the &lt;code&gt;knife&lt;/code&gt; command earlier, is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Requirements - e.g. other cookbook dependencies, platforms supported&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attributes - List (or better yet, a table) of attributes you cookbook uses, with their default values&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Usage - Which recipe to run - usually ::default.rb&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Contributing Guide - if you cookbook is open source/public&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;License &amp;amp; Authors&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;metadata-rb&#34;&gt;metadata.rb&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/metadata.rb&#34;&gt;https://github.com/feedhenry-cookbooks/gitlab-shell/blob/master/metadata.rb&lt;/a&gt; This is the most imporant file when uploading your cookbook. It contains the cookbook name &amp;amp; version number, among other things:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;name             &#39;gitlab-shell&#39;
maintainer       &#39;FeedHenry&#39;
maintainer_email &#39;david.martin@feedhenry.com&#39;
license          &#39;All rights reserved&#39;
description      &#39;Installs/Configures gitlab-shell&#39;
long_description IO.read(File.join(File.dirname(__FILE__), &#39;README.md&#39;))
version          &#39;0.3.0&#39;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ever time we want to publish our cookbook, we should bump the version number. This ensures we keep a history of the coookbook and don&amp;rsquo;t break it for users of previous versions. When we&amp;rsquo;re happy that everything is in order &amp;amp; ready to go, the publish command is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;knife cookbook site share -k ~/.chef/&amp;lt;userid&amp;gt;.pem &amp;quot;&amp;lt;cookbook_name&amp;gt;&amp;quot; &amp;quot;&amp;lt;category&amp;gt;&amp;quot; -u &amp;lt;userid&amp;gt; -VV -o &amp;lt;cookbook_location&amp;gt;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;knife cookbook site share -k ~/.chef/davidmartin.pem &amp;quot;gitlab-shell&amp;quot; &amp;quot;Other&amp;quot; -u davidmartin -VV -o ~/work
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More details on the &lt;code&gt;knife cookbook site&lt;/code&gt; command, including available categories, can be found here &lt;a href=&#34;https://docs.getchef.com/knife_cookbook_site.html&#34;&gt;https://docs.getchef.com/knife_cookbook_site.html&lt;/a&gt; After publishing, we can find our cookbook by searching on the Chef Supermarket &lt;a href=&#34;https://supermarket.getchef.com/cookbooks&#34;&gt;https://supermarket.getchef.com/cookbooks&lt;/a&gt; The finished product for this article can be found at &lt;a href=&#34;https://supermarket.getchef.com/cookbooks/gitlab-shell&#34;&gt;https://supermarket.getchef.com/cookbooks/gitlab-shell&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;using-the-cookbook&#34;&gt;Using the cookbook&lt;/h1&gt;

&lt;p&gt;Using the cookbook is simple. In your Chef project, add the following line to your Chefile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;cookbook &#39;gitlab-shell&#39;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and run&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;librarian-chef install
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;after which you should see the cookbook installed into cookbooks/gitlab-shell in your project.&lt;/p&gt;

&lt;h1 id=&#34;credit&#34;&gt;Credit&lt;/h1&gt;

&lt;p&gt;Credit goes to the maintainers of the gitlab cookbook at &lt;a href=&#34;https://gitlab.com/gitlab-org/cookbook-gitlab/tree/master&#34;&gt;https://gitlab.com/gitlab-org/cookbook-gitlab/tree/master&lt;/a&gt;. This gitlab-shell cookbook is a subset of the gitlab cookbook.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Web Scraping for Fun &amp; Profit</title>
      <link>http://feedhenrydevblogarchive.github.io/web-scraping-fun-profit/</link>
      <pubDate>Tue, 30 Sep 2014 19:15:58 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/web-scraping-fun-profit/</guid>
      <description>

&lt;p&gt;There’s a number of ways to retrieve data from a backend system within mobile projects. In an ideal world, everything would have a RESTful JSON API - but often, this isn’t the case.Sometimes, SOAP is the language of the backend. Sometimes, it’s some proprietary protocol which might not even be HTTP-based. Then, there’s scraping.&lt;/p&gt;

&lt;p&gt;Retrieving information from web sites as a human is easy. The page communicates information using stylistic elements like headings, tables and lists - this is the communication protocol of the web. Machines retrieve information with a focus on structure rather than style, typically using communication protocols like XML or JSON. Web scraping attempts to bridge this human protocol into a machine-readable format like JSON. This is what we try to achieve with web scraping.&lt;/p&gt;

&lt;p&gt;As a means of getting to data, it don’t get much worse than web scraping. Scrapers were often built with Regular Expressions to retrieve the data from the page. Difficult to craft, impossible to maintain, this means of retrieval was far from ideal. The risks are many - even the slightest layout change on a web page can upset scraper code, and break the entire integration. It’s a fragile means for building integrations, but sometimes it’s the only way.&lt;/p&gt;

&lt;p&gt;Having built a scraper service recently, the most interesting observation for me is how far we’ve come from these “dark days”. Node.js, and the massive ecosystem of community built modules has done much to change how these scraper services are built.&lt;/p&gt;

&lt;h2 id=&#34;effectively-scraping-information&#34;&gt;Effectively Scraping Information&lt;/h2&gt;

&lt;p&gt;Websites are built on the Document Object Model, or DOM. This is a tree structure, which represents the information on a page.By interpreting the source of a website as a DOM, we can retrieve information much more reliably than using methods like regular expression matching. The most popular method of querying the DOM is using jQuery, which enables us to build powerful and maintainable queries for information. The &lt;a href=&#34;https://github.com/tmpvar/jsdom&#34;&gt;JSDom&lt;/a&gt; Node module allows us to use a DOM-like structure in serverside code.&lt;/p&gt;

&lt;p&gt;For purpose of Illustration, we&amp;rsquo;re going to scrape the blog page of FeedHenry&amp;rsquo;s website. &lt;a href=&#34;https://gist.github.com/cianclarke/78b67dd614403cd90fb8&#34;&gt;I’ve built a small code snippet&lt;/a&gt; that retrieves the contents of the blog, and translates it into a JSON API. To find the queries I need to run, first I need to look at the HTML of the page. To do this, in Chrome, I right-click the element I&amp;rsquo;m looking to inspect on the page, and click &amp;ldquo;Inspect Element&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_5025&amp;rdquo; align=&amp;ldquo;alignnone&amp;rdquo; width=&amp;ldquo;631&amp;rdquo;]&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-10.44.38.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-10.44.38.png&#34; alt=&#34;Screen Shot 2014-09-30 at 10.44.38&#34; /&gt;&lt;/a&gt; Articles on the FeedHenry blog are a series of &amp;lsquo;div&amp;rsquo; elements with the &amp;lsquo;.itemContainer&amp;rsquo; class[/caption]&lt;/p&gt;

&lt;p&gt;Searching for a pattern in the HTML to query all blog post elements, we construct the &lt;code&gt;div.itemContainer&lt;/code&gt; query. In jQuery, we can iterate over these using the .each method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var posts = [];
$(&#39;div.itemContainer&#39;).each(function(index, item){
  // Make JSON objects of every post in here, pushing to the posts[] array
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From there, we pick off the heading, author and post summary using a child selector on the original post, querying the relevant semantic elements:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/scrapingChildElements.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/scrapingChildElements.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Post Title, using jQuery:&lt;/p&gt;

&lt;p&gt;$(item).find(&amp;lsquo;h3&amp;rsquo;).text()trim() // trim, because titles have white space either side&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Post Author, using jQuery:&lt;/p&gt;

&lt;p&gt;$(item).find(&amp;lsquo;.catItemAuthor a&amp;rsquo;).text()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Post Body, using jQuery:&lt;/p&gt;

&lt;p&gt;$(item).find(&amp;lsquo;p&amp;rsquo;).text()&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Adding some JSDom magic to our snippet, and pulling together the above two concept (iterating through posts, and picking off info from each post), we get &lt;a href=&#34;https://gist.github.com/cianclarke/78b67dd614403cd90fb8&#34;&gt;this snippet&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var request = require(&#39;request&#39;),
jsdom = require(&#39;jsdom&#39;);

jsdom.env(
  &amp;quot;http://www.feedhenry.com/category/blog&amp;quot;,
  [&amp;quot;http://code.jquery.com/jquery.js&amp;quot;],
  function (errors, window) {
    var $ = window.$, // Alias jQUery
    posts = [];
    $(&#39;div.itemContainer&#39;).each(function(index, item){
      item = $(item); // make queryable in JQ
      posts.push({
        heading : item.find(&#39;h3&#39;).text().trim(),
        author : item.find(&#39;.catItemAuthor a&#39;).text(),
        teaser : item.find(&#39;p&#39;).text()
      });
    });
    console.log(posts);
  }
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-11.03.52.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-11.03.52-300x91.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-note-on-building-css-queries&#34;&gt;A note on building CSS Queries&lt;/h3&gt;

&lt;p&gt;As with styling web sites with CSS, building effective CSS queries is equally as important when building a scraper. It&amp;rsquo;s important to build queries that are not too specific, or likely to break when the structure of the page changes. Equally important is to pick a query that is not too general, and likely to select extra data from the page you don&amp;rsquo;t want to retrieve.&lt;/p&gt;

&lt;p&gt;A neat trick for generating the relevant selector statement is to use Chrome&amp;rsquo;s &amp;ldquo;CSS Path&amp;rdquo; feature in the inspector. After finding the element in the inspector panel, right click, and select &amp;ldquo;Copy CSS Path&amp;rdquo;. This method is good for individual items, but for picking repeating patterns (like blog posts), this doesn&amp;rsquo;t work though. Often, the path it gives is much too specific, making for a fragile binding. Any changes to the page&amp;rsquo;s structure will break the query.&lt;/p&gt;

&lt;h2 id=&#34;making-a-re-usable-scraping-service&#34;&gt;Making a Re-usable Scraping Service&lt;/h2&gt;

&lt;p&gt;Now that we&amp;rsquo;ve retrieved information from a web page, and made some JSON, let&amp;rsquo;s build a reusable API from this. We&amp;rsquo;re going to make a FeedHenry Blog Scraper service in FeedHenry3. For those of you not familiar with service creation, see &lt;a href=&#34;http://www.feedhenry.com/creating-re-usable-mbaas-services-feedhenry-3/&#34;&gt;this video walkthrough.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re going to start by creating a &amp;rdquo;new mBaaS Service&amp;rdquo;, rather than selecting one of the off-the-shelf services. To do this, we modify the &lt;code&gt;application.js&lt;/code&gt; file of our service to include one route, &lt;code&gt;/blog&lt;/code&gt;, which includes our code snippet from earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// just boilerplate scraper setup
var mbaasApi = require(&#39;fh-mbaas-api&#39;),
express = require(&#39;express&#39;),
mbaasExpress = mbaasApi.mbaasExpress(),
cors = require(&#39;cors&#39;),
request = require(&#39;request&#39;),
jsdom = require(&#39;jsdom&#39;);

var app = express();
app.use(cors());
app.use(&#39;/sys&#39;, mbaasExpress.sys([]));
app.use(&#39;/mbaas&#39;, mbaasExpress.mbaas);
app.use(mbaasExpress.fhmiddleware());
// Our /blog scraper route
app.get(&#39;/blog&#39;, function(req, res, next){
  jsdom.env(
    &amp;quot;http://www.feedhenry.com/category/blog&amp;quot;,
    [&amp;quot;http://code.jquery.com/jquery.js&amp;quot;],
    function (errors, window) {
      var $ = window.$, // Alias jQUery
      posts = [];
      $(&#39;div.itemContainer&#39;).each(function(index, item){
        item = $(item); // make queryable in JQ
        posts.push({
          heading : item.find(&#39;h3&#39;).text().trim(),
          author : item.find(&#39;.catItemAuthor a&#39;).text(),
          teaser : item.find(&#39;p&#39;).text()
        });
      });
      return res.json(posts);
    }
  );
});
app.use(mbaasExpress.errorHandler());

var port = process.env.FH_PORT || process.env.VCAP_APP_PORT || 8001;
var server = app.listen(port, function() {});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re also going to write some &lt;a href=&#34;http://docs.feedhenry.com/v3/product_features/services.html#services-service_documentation&#34;&gt;documentation for our service&lt;/a&gt;, so we (and other developers) can interact with it using the FeedHenry discovery console. We&amp;rsquo;re going to modify the &lt;code&gt;README.md&lt;/code&gt; file to document what we&amp;rsquo;ve just done using &lt;a href=&#34;http://apiblueprint.org/&#34;&gt;API Blueprint&lt;/a&gt; documentation format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# FeedHenry Blog Web Scraper
This is a feedhenry blog scraper service. It uses the `JSDom` and `request` modules to retrieve the contents of the FeedHenry developer blog, and parse the content using jQuery.
# Group Scraper API Group
# blog [/blog]
Blog Endpoint
## blog [GET]
Get blog posts endpoint, returns JSON data.
+ Response 200 (application/json)
    + Body
            [{ blog post}, { blog post}, { blog post}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now try out the scraper service in the studio, and see the response:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-15.03.10.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/09/Screen-Shot-2014-09-30-at-15.03.10-300x252.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;scraping-the-ultimate-in-api-creation&#34;&gt;Scraping - The Ultimate in API Creation?&lt;/h2&gt;

&lt;p&gt;Now that I&amp;rsquo;ve described some modern techniques for effectively scraping data from web sites, it&amp;rsquo;s time for some major caveats. First,  WordPress blogs like ours already have feeds and APIs available to developers - there&amp;rsquo;s no need to ever scrape any of this content. Web Scraping is &lt;strong&gt;not a replacement for an API&lt;/strong&gt;. It should be used only as a &lt;strong&gt;last resort&lt;/strong&gt;, after every endeavour to discover an API has already been made. Using a web scraper in a commercial setting requires much time set aside to maintain the queries, and an agreement with the source data is being scraped on to alert developers in the event the page changes structure.
With all this in mind, it can be a useful tool to iterate quickly on an integration when waiting for an API, or as a fun hack project.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.twitter.com/cianclarke&#34;&gt;@cianclarke&lt;/a&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/06/Screen-Shot-2014-06-11-at-15.56.07.png&#34;&gt; &lt;/a&gt;is a Software Engineer with FeedHenry. Primarily focused on the mobile-backend-as-a-service space, Cian is responsible for many of FeedHenry&amp;rsquo;s mBaaS developer features.&lt;/em&gt;
  *[mBaaS]: Mobile Backend As A Service&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Import and integrate your existing apps into FeedHenry 3 in 12 minutes</title>
      <link>http://feedhenrydevblogarchive.github.io/import-integrate-existing-apps-feedhenry-3-12-minutes/</link>
      <pubDate>Wed, 16 Jul 2014 09:04:45 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/import-integrate-existing-apps-feedhenry-3-12-minutes/</guid>
      <description>&lt;p&gt;FeedHenry 3 offers a range of App importing and on-boarding options including Cordova, Native Android, Native iOS, Native Windows Phone 8, Web Apps, Appcelerator and Xamarin Apps. Our built-in Git support means that you can either manage all of the source code in our Git servers or make use of Git’s power to push/pull code from your existing Git repositories into/out-of FeedHenry.&lt;/p&gt;

&lt;p&gt;Integrating the FeedHenry SDKs into your Apps so that they can make use of the FeedHenry back-end services, including the mBaaS, is extremely easy and the Studio walks you through all of the steps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2014/07/import.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this video, Jason shows you how to import and integrate an iOS app into FeedHenry 3. He does this in 12 minutes flat and so can you!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vimeo.com/100323062&#34;&gt;FeedHenry 3 - App Import&lt;/a&gt; from &lt;a href=&#34;http://vimeo.com/feedhenry&#34;&gt;FeedHenry Ltd.&lt;/a&gt; on &lt;a href=&#34;https://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>iBeacons: A Primer in Proximity Programming</title>
      <link>http://feedhenrydevblogarchive.github.io/ibeacons-primer/</link>
      <pubDate>Thu, 01 May 2014 21:37:54 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/ibeacons-primer/</guid>
      <description>

&lt;p&gt;iBeacons are a low-power bluetooth device Apple quietly release as part of the iOS7 launch recently. They&amp;rsquo;re the Apple alternative to NFC, a small location aware device which developers can use to track user&amp;rsquo;s proximity to a location, and trigger various actions in a mobile app. Potential use cases include payments, exhibit information, proximity advertising and promotions (read: spam),  and many more besides. iBeacons are a departure from the normal way Apple deals with Hardware  - interestingly, any vendor is free to make iBeacons which will work with Apple SDKs. The devices are both simple and cheap, and it&amp;rsquo;s pretty easy to hack one together with a Raspberry Pi and a bluetooth receiver, or an old iPhone.&lt;/p&gt;

&lt;h2 id=&#34;what-is-an-ibeacon&#34;&gt;What is an iBeacon?&lt;/h2&gt;

&lt;p&gt;An iBeacon is a Bluetooth Low Energy device that transmits some important information back to a mobile device to identify it, and it&amp;rsquo;s location.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Proximity UUID:&lt;/strong&gt; The &amp;lsquo;unique&amp;rsquo; identifier of this type of iBeacon. Unfortunately, this isn&amp;rsquo;t unique at all  - more on that later.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Major:&lt;/strong&gt; A number that identifies a group of iBeacons, e.g. all those deployed within a specific store&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Minor:&lt;/strong&gt; A number (which at least should be unique - finally!) to identify the specific device&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Proximity:&lt;/strong&gt; A number which identifies how close the beacon is - Far, Near or Immediate.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;identifying-ibeacons&#34;&gt;Identifying iBeacons&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://res.cloudinary.com/cianclarke/image/upload/c_scale,w_225/v1398957797/photo1_1_k7twsu.jpg&#34; alt=&#34;&#34; /&gt;As eluded to in the above bullet points, the UUID is not unique. If you&amp;rsquo;ve made your own iBeacons, great, you&amp;rsquo;ll use this number to identify all the beacons you&amp;rsquo;ve made.
If you&amp;rsquo;ve bought iBeacons, they&amp;rsquo;ll already have been assigned an UUID by the manufacture. Here&amp;rsquo;s where things get a little messy - manufacturers don&amp;rsquo;t always provide the end user with the UUID. This locks you into using their SDK toolset (no thank you), rather than just interfacing directly with the iBeacons using the iOS SDK APIs.
Some quick googling reveals the UUID of some common iBeacon manufactures - as to which one, it&amp;rsquo;s just trial and error I&amp;rsquo;m afraid:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Roximity: 8DEEFBB9-F738-4297-8040-96668BB44281 || 8deefbb9-f738-4297-8040-96668bb44281 [2]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Estimote: B9407F30-F5F8-466E-AFF9- 25556B57FE6D [3]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kontakt: ed3a6985-8872-4bb7-b784-c59ef3589844 [4]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that you have the Proximity UUID, you can start ranging for iBeacons in your app. All three of our Beacons were identical in every way - there was no unique identifier on the casing, so I enabled the beacons one by one, &lt;a href=&#34;https://github.com/cianclarke/iBeacons-primer/blob/hardcoded-beacons/BeaconReceiver/ViewController.m#L79&#34;&gt;logging the Major and Minor IDs as I went&lt;/a&gt;. Turns out, all our beacons have a Major ID of 1, and unique minor IDs.
Taking note of this, and reaching into my developer toolkit, there&amp;rsquo;s two things I did. First,  we can construct a simple &lt;a href=&#34;https://github.com/cianclarke/iBeacons-primer/blob/hardcoded-beacons/BeaconReceiver/ViewController.m#L82-L105&#34;&gt;switch statement that does special logic for each beacon&lt;/a&gt; in our iOS app. Then, I use a very advanced piece of equipment known as a Sharpie, so I don&amp;rsquo;t mix up the beacons!&lt;/p&gt;

&lt;h2 id=&#34;a-note-on-proximity&#34;&gt;A note on Proximity&lt;/h2&gt;

&lt;p&gt;The proximity of these devices isn&amp;rsquo;t particularly precise. The near and immediate values in particular look to fluctuate quite rapidly. For accurate readings, some slightly more complex logic than illustrated in this example code may be needed in the &lt;a href=&#34;https://github.com/cianclarke/iBeacons-primer/blob/hardcoded-beacons/BeaconReceiver/ViewController.m#L53&#34;&gt;didRangeBeacons delegate function&lt;/a&gt;, for example taking an average proximity across the last N calls.&lt;/p&gt;

&lt;p&gt;Another interesting observation I made was that across our three small offices, all adjacent, the &amp;lsquo;near&amp;rsquo; value wasn&amp;rsquo;t wide enough to distinguish one from the other, and the &amp;lsquo;immediate&amp;rsquo; value was too close to identify an office. It seems these devices don&amp;rsquo;t function well on such a small location scale.&lt;/p&gt;

&lt;h2 id=&#34;enter-mbaas&#34;&gt;Enter mBaaS&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve hardcoded a few iBeacon Secondary IDs and the relevant responses for these in a switch statement - but let&amp;rsquo;s make this a little more dynamic. I&amp;rsquo;ve added my project to FeedHenry, and I&amp;rsquo;m going to make use of the FeedHenry Data Browser to set up a collection of iBeacons that I can easily mange. I&amp;rsquo;m also going to write &lt;a href=&#34;https://gist.github.com/cianclarke/272fae631ab34ac38161#file-beacons-js-L5-L19&#34;&gt;some simple cloud code&lt;/a&gt; to return an object of iBeacon minor ID key, object value pairs back to the client.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_646&amp;rdquo; align=&amp;ldquo;alignnone&amp;rdquo; width=&amp;ldquo;594&amp;rdquo;]&lt;img src=&#34;http://res.cloudinary.com/cianclarke/image/upload/v1398957033/Screen_Shot_2014-05-01_at_11_10_02_qdolou.png&#34; alt=&#34;&#34; /&gt; My project setup in FeedHenry mBaaS[/caption]&lt;/p&gt;

&lt;p&gt;Lastly, I&amp;rsquo;ve altered the mobile app to &lt;a href=&#34;https://github.com/cianclarke/iBeacons-primer/blob/master/BeaconReceiver/ViewController.m#L40-L56&#34;&gt;request the list of iBeacons from the FeedHenry cloud&lt;/a&gt;, and &lt;a href=&#34;https://github.com/cianclarke/iBeacons-primer/blob/master/BeaconReceiver/ViewController.m#L92-L102&#34;&gt;draw the label, sublabel, and colour from this description&lt;/a&gt;. I can now easily change my iBeacon text labels and colours that show when the beacon enters range.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a video of it all in action:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=E9XkkeTpxNg&#34;&gt;http://www.youtube.com/watch?v=E9XkkeTpxNg&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-about-indoor-mapping&#34;&gt;How about Indoor Mapping?&lt;/h2&gt;

&lt;p&gt;One of the big implications of these new devices is their potential use for indoor mapping. Unfortunately, the usefulness of three beacon which can transmit no more than signal strength (and thus, in turn, an estimation of proximity as we use above) makes for a poor location monitoring device out of the box. I tried some simple triangulation logic, and took the beacons into the car park of our office. Although there was clearly some consistency in the (x,y) coordinate pairs I was receiving at each beacon, I found no correlation between the number range at each triangular point and a cartesian plane.
In summary: Unless you have a lot of time on your hands, or a higher level API becomes available for triangulating position based on iBeacons, it&amp;rsquo;s probably not worth the effort.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There are plenty of potential applications for this technology in retail, manufacturing, museums, healthcare, and more besides! Of course, this iOS demo app could be expanded to more advanced uses of the iBeacon SDK - but this quick example illustrates the concepts. Hopefully this primer shows how to get up and running with iBeacons, and illustrates how easy it is to manage these in the FeedHenry cloud.&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&#34;https://developer.apple.com/library/ios/documentation/userexperience/conceptual/LocationAwarenessPG/RegionMonitoring/RegionMonitoring.html (Monitoring&#34;&gt;https://developer.apple.com/library/ios/documentation/userexperience/conceptual/LocationAwarenessPG/RegionMonitoring/RegionMonitoring.html (Monitoring&lt;/a&gt; Beacon Regions)&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&#34;http://stackoverflow.com/questions/21208634/detect-roximity-ibeacon-without-roximity-sdk&#34;&gt;http://stackoverflow.com/questions/21208634/detect-roximity-ibeacon-without-roximity-sdk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&#34;https://community.estimote.com/hc/en-us/articles/200761958-Advertising-Packet-Estimote-s-Proximity-UUID&#34;&gt;https://community.estimote.com/hc/en-us/articles/200761958-Advertising-Packet-Estimote-s-Proximity-UUID&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&#34;http://docs.kontakt.io/beacon/kontakt-beacon-v1.pdf&#34;&gt;http://docs.kontakt.io/beacon/kontakt-beacon-v1.pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FeedHenry update on Heartbleed (SSL Security Vulnerability CVE-2014-0160)</title>
      <link>http://feedhenrydevblogarchive.github.io/feedhenry-update-heartbleed-ssl-security-vulnerability-cve-2014-0160/</link>
      <pubDate>Wed, 09 Apr 2014 18:35:51 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/feedhenry-update-heartbleed-ssl-security-vulnerability-cve-2014-0160/</guid>
      <description>&lt;p&gt;As you may know, the Internet is abuzz with stories surrounding the extremely serious OpenSSL security vulnerability (CVE-2014-0160) which has become known as &amp;ldquo;Heartbleed&amp;rdquo;. For an in-depth explanation of this issue, visit &lt;a href=&#34;http://heartbleed.com/&#34;&gt;heartbleed.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;FeedHenry has conducted a review of all its publicly-hosted cloud infrastructure and can confirm that none of its Enterprise cloud platforms were found to be vulnerable to this issue. If you have any questions about this, please contact our &lt;a href=&#34;http://support.feedhenry.com&#34;&gt;Support team&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Server side PDF generation with Node.js</title>
      <link>http://feedhenrydevblogarchive.github.io/server-side-pdf-generation-node-js/</link>
      <pubDate>Fri, 21 Feb 2014 16:45:55 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/server-side-pdf-generation-node-js/</guid>
      <description>

&lt;h1 id=&#34;overview-of-what-was-required&#34;&gt;Overview of what was required&lt;/h1&gt;

&lt;p&gt;A solution in Node.js for dynamically generating a PDF version of submitted form data.
The form data is stored in a mongo database, backed by some mongoose models. What this boils down to is we have a collection (JSON array) of forms (JSON objects) with a number of key-value pairs. These key-value pairs have to be written out to a PDF file. The layout of the PDF file could be tweaked later to present the data in the best possible way. The tricky part was how to create the PDF file and add content to it.&lt;/p&gt;

&lt;h1 id=&#34;options-for-creating-pdfs&#34;&gt;Options for creating PDFs&lt;/h1&gt;

&lt;h2 id=&#34;pdfkit&#34;&gt;PDFKit&lt;/h2&gt;

&lt;p&gt;The first option explored was PDFKit, &amp;lsquo;a PDF generation library for Node.js&amp;rsquo; &lt;a href=&#34;http://pdfkit.org/&#34;&gt;http://pdfkit.org/&lt;/a&gt;. The API looked good, but it was too high level. It would require a lot of time to get a dynamically generated layout working. This was an important factor as the order, types and number of fields to include in the PDF would be outside our control e.g. there could be any number of text fields followed by any number of image files, which could span multiple pages. Calculating where to put each of these would require a lot of time to get right, especially trying to prevent images spanning the bottom of 1 page and the top of the next page.&lt;/p&gt;

&lt;p&gt;The next 2 options took a different approach of converting html to pdf. By working with html, it would allow us to get a nicer layout together much quicker. It also meant we could leverage existing experience with html &amp;amp; css.&lt;/p&gt;

&lt;h2 id=&#34;wkhtmltopdf&#34;&gt;Wkhtmltopdf&lt;/h2&gt;

&lt;p&gt;wkhtmltopdf, &lt;a href=&#34;https://code.google.com/p/wkhtmltopdf/&#34;&gt;https://code.google.com/p/wkhtmltopdf/&lt;/a&gt;, is a shell tool for converting html to pdf by using the webkit rendering engine. There is a Node.js module, by the same name, that wraps this shell tool &lt;a href=&#34;https://npmjs.org/package/wkhtmltopdf&#34;&gt;https://npmjs.org/package/wkhtmltopdf&lt;/a&gt;. It looks like a great tool and provides a lot of features. However, we didn&amp;rsquo;t choose this option because we were more familiar with the next option.&lt;/p&gt;

&lt;h2 id=&#34;phantomjs&#34;&gt;PhantomJS&lt;/h2&gt;

&lt;p&gt;The third, and chosen option, was to use the built in PDF rendering capabilities of PhantomJS. PhantomJS is a headless WebKit with a javascript API. The API allows for writing acceptance tests, capturing screenshots or simply rendering and modifying html in a server-side environment. There are plenty of Node.js modules available to integrate with PhantomJS. We chose phantomjs-node &lt;a href=&#34;https://github.com/sgentle/phantomjs-node&#34;&gt;https://github.com/sgentle/phantomjs-node&lt;/a&gt;. We&amp;rsquo;re very familiar with PhantomJS, and use it for unit and functional tests for our frontend systems (via grunt &lt;a href=&#34;http://gruntjs.com/&#34;&gt;http://gruntjs.com/&lt;/a&gt;) and html5 Apps. This familiarily made the choice easier, but still left a few challenges.&lt;/p&gt;

&lt;h1 id=&#34;phantomjs-solution&#34;&gt;PhantomJS Solution&lt;/h1&gt;

&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;

&lt;p&gt;Rendering a PDF was the easiest part. Theres an API call &lt;a href=&#34;http://phantomjs.org/api/webpage/method/render.html&#34;&gt;http://phantomjs.org/api/webpage/method/render.html&lt;/a&gt;. The generated PDF is saved to disk with the given filename.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;page.render(&#39;/tmp/file.pdf&#39;, function() {
  // file is now written to disk
});
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some challenges to solve were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;how to control the size of the PDF i.e. have an A4 page size&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;how to dynamically build the html content&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;how to style the content in the PDF&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;how to load/inject images into the PDF&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;controlling-the-viewport-size&#34;&gt;Controlling the viewport size&lt;/h3&gt;

&lt;p&gt;There&amp;rsquo;s a page API for setting the page size. The exact dimensions of the pages can be set, or the format can be specified e.g. A4.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;page.set(&#39;paperSize&#39;, {
  format: &#39;A4&#39;
}, function() {
  // continue with page setup
});
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dynamically-building-the-pdf-content&#34;&gt;Dynamically building the PDF content&lt;/h3&gt;

&lt;p&gt;How to build the html dynamically was an easy decision. We went with a Handlebars template &lt;a href=&#34;http://handlebarsjs.com/&#34;&gt;http://handlebarsjs.com/&lt;/a&gt;, and iterated over each of the form fields, constructing a different block of html depending on the field type. e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;{{#each fields}}
  {{#is &#39;file&#39; type}}
    &amp;lt;a href=&amp;quot;{{this.downloadUrl}}&amp;quot;&amp;gt;{{this.downloadUrl}}&amp;lt;/a&amp;gt;&amp;lt;br/&amp;gt;
  {{/is}}

  {{#is &#39;number&#39; &#39;radio&#39; type}}
    &amp;lt;span&amp;gt;{{this}}&amp;lt;/span&amp;gt;
  {{/is}}

  {{#is &#39;text&#39; &#39;emailAddress&#39; &#39;dropdown&#39; type}}
    &amp;lt;p&amp;gt;{{this}}&amp;lt;/p&amp;gt;
  {{/is}}
{{/each}}
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;styling-the-pdf-content&#34;&gt;Styling the PDF content&lt;/h3&gt;

&lt;p&gt;Styling was done with CSS. Some specific styles were added to ensure images never overflow vertically (across pages) or horizontally (partially visible). An extra class was added to allow forcing a page break too.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;* {
  overflow: visible !important; // forces a built-in PDF rendering gotcha in WebKit so that images never span 2 pages
}
img {
  margin-top:20px;
  max-width: 92%; // images will never overflow off the right hand side of a page
}
.page-break {
  display: block;
  page-break-before: always; // force a page break
}
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;loading-injecting-images-into-the-pdf-content&#34;&gt;Loading/Injecting images into the PDF content&lt;/h3&gt;

&lt;p&gt;Images for the PDF are, like the rest of the content, private and stored behind an auth protected server. This meant that writing the src url of images as a direct image url wouldn&amp;rsquo;t work. A Cookie could have been added to the PhantomJS session, but that posed other problems. Also, fetching remote images would have slowed down the rendering time.
To get around this problem, we retrieved any images needed for the PDF directly from gridfs, and saved them to the local filesystem. This allowed us to use the local filesystem image url e.g. file:///tmp/image.png.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;&amp;lt;!-- Load image from file:///, will have been pre-saved to disk --&amp;gt;
&amp;lt;img src=&amp;quot;{{this.localUrl}}&amp;quot;/&amp;gt;&amp;lt;br/&amp;gt;
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;extra-challenges&#34;&gt;Extra Challenges&lt;/h2&gt;

&lt;p&gt;Adding this solution to a running Node.js server posed a couple of extra challenges:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;how to download the PDF file&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;how to avoid the time overhead of initialising the PhantomJS process for every PDF render&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;how to avoid the PhantomJS process hanging around when the Node.js server stops&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;downloading-the-generated-pdf-in-express&#34;&gt;Downloading the generated PDF in express&lt;/h3&gt;

&lt;p&gt;Our server that would generate these PDF&amp;rsquo;s was a Node.js server using expressjs &lt;a href=&#34;http://expressjs.com/&#34;&gt;http://expressjs.com/&lt;/a&gt;. Theres a handy one-liner in express to initiate a file download for a file on disk &lt;a href=&#34;http://expressjs.com/api.html#res.download&#34;&gt;http://expressjs.com/api.html#res.download&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;res.download(&#39;/file.pdf&#39;, &#39;file:///tmp/file.pdf&#39;);
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;avoiding-phantomjs-init-for-every-pdf-generation&#34;&gt;Avoiding PhantomJS init for every PDF generation&lt;/h3&gt;

&lt;p&gt;The initial overhead of starting phantom was ~1-3 seconds. This meant a file download would take some time before the download actually began. To get around this, we only created a PhantomJS session if one was not already running, and keep a reference to it. Each PDF render would happen in a new page inside the same session. We had to ensure the page was closed when the rendering complete (or if the rendering failed). Creating a new page inside an existing PhantomJS session is a lot quicker than starting a new session.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;var renderPdf = function(session, cb) {
  var page;

  try {
    session.createPage(function(_page) {
      page = _page;
      // ...
      var file = &#39;/tmp/file.pdf&#39;;
      page.render(file, function() {
        page.close();
        page = null;
        return cb(null, file);
      });
    });
  } catch(e) {
    try {
      if (page != null) {
        page.close(); // try close the page in case it opened but never rendered a pdf due to other issues
      }
    } catch(e) {
      // ignore as page may not have been initialised
    }
    return cb(&#39;Exception rendering pdf:&#39; + e.toString());
  }
};
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;avoiding-phantomjs-processes-hanging-around&#34;&gt;Avoiding PhantomJS processes hanging around&lt;/h3&gt;

&lt;p&gt;If the Node.js server was to stop (either intentially or a crash) and a PhantomJS session was open, the associated PhantomJS process would stay running. This would caused issues with extra resources being used and port conflicts when the server was restarted (PhantomJS listens on a few ports).
To prevent this from happening, we had to add a best effort attempt to shutdown the session when the Node.js server exits.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code&amp;gt;var session;
var createPhantomSession = function(cb) {
  if (session) {
    return cb(null, session);
  } else {
    require(&#39;phantom&#39;).create({}, function(_session) {
      session = _session;
      return cb(null, session);
    });
  }
};

process.on(&#39;exit&#39;, function(code, signal) {
  session.exit();
});
&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;There are so many ways that this feature could have been implemented. The choices made above were driven by a few main factors:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Familiarity &amp;amp; previous experience with the tools &amp;amp; modules available&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Research into available technologies&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Personal choice&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Performance implications of a paritcular solution&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some time was spent on performance testing during development. Various scenarios were run on the best way to start/stop a phantom session, and how best to use session pages, if at all. Each run generated a total of 100 PDFs. Results show observed time, cpu &amp;amp; memory for PhantomJS and Node.js for each scenario. The first run had the following critera:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;create and teardown a phantomjs session for each page being rendered to PDF&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;load (1) image remotely from web server with an auth cookie&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;modify image source with jQuery after page is rendered (this wasnt needed in the end)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;was not calling page.close after each page rendered (leaving processes hanging around)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;table &gt;&lt;/p&gt;

&lt;p&gt;&lt;tr &gt;
Comment
Time
Phantomjs Max CPU
Phantomjs Max Mem
Node Max CPU
Node Max Mem
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tbody &gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Create and teardown a phantom session each time
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;1m47.205s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a (too quick)
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a (too quick)
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;2%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;330M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Create and leave a single phantom session open
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;0m19.954s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;95%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;338M
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;2%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;130M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Same as above,but calling page.close() after each gen
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;0m20.645s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;95%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;275M
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;2%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;130M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;same as above,but all in parallel i.e. open 100 pages in phantomjs
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;0m22.139s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;100%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;700M
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;2%
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;117M
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;same as above,but with jQuery loading/DOM manipulation removed
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;0m17.497s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;same as above,but with image loading using file:///
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: center;&#34; &gt;0m14.655s
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td style=&#34;text-align: right;&#34; &gt;n/a
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
Although this was a lightweight test, it showed some useful information. The outcome of this can be summarised in the following notes (taken after an initial &amp;lsquo;spike&amp;rsquo; and prior to the actual implementation):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;creating a new phantom session for each pdf generation is slow, so best to keep a single phantomjs session alive and create pages as required.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;need to ensure phantom session is closed on process exit (prevent phantomjs processes hanging about)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ensure the page is &amp;lsquo;closed&amp;rsquo; each time after pdf generation to release memory &lt;a href=&#34;https://github.com/ariya/phantomjs/wiki/API-Reference-WebPage#wiki-webpage-close&#34;&gt;https://github.com/ariya/phantomjs/wiki/API-Reference-WebPage#wiki-webpage-close&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;avoid injecting external scripts if possible, jQuery in particular, as this can slow down the generation process&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;avoid evaluating code in the phantom page if possible as this causes extra requests over the phantom bridge &lt;a href=&#34;https://github.com/ariya/phantomjs/wiki/API-Reference-WebPage#evaluatefunction-arg1-arg2--object&#34;&gt;https://github.com/ariya/phantomjs/wiki/API-Reference-WebPage#evaluatefunction-arg1-arg2&amp;ndash;object&lt;/a&gt;. Better to include any required js in the initial content&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;avoid loading remote images as this adds time compared to loading files from disk (Overhead of retrieving binary from gridfs is less than retrieving image via http auth protected endpoint)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;based on load tests, the best solution to avoid heavy cpu and memory usage is to not have any concurrency with pdf generation, and to use a queue. (However this recommendation was deferred due to expected load not being an issue currently)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A time limit could be imposed on pdf generation to avoid the queue hanging. Tests indicate that at best, a simple pdf can be generated every 150ms (~7/second). This time will vary depending on the number images/files and fields.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;requirements-fulfilled&#34;&gt;Requirements Fulfilled&lt;/h1&gt;

&lt;p&gt;This solution uses a variety of Node.js modules, and PhantomJS, a cross OS tool that allows use to convert html to PDF.
An overview of some of the modules used:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;phantomjs-node &lt;a href=&#34;https://github.com/sgentle/phantomjs-node&#34;&gt;https://github.com/sgentle/phantomjs-node&lt;/a&gt; (PhantomJS integration module for NodeJS)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Handlebars &lt;a href=&#34;https://github.com/wycats/handlebars.js/&#34;&gt;https://github.com/wycats/handlebars.js/&lt;/a&gt; (For dynamic templating)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Express &lt;a href=&#34;https://github.com/visionmedia/express&#34;&gt;https://github.com/visionmedia/express&lt;/a&gt; (Web framework)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mongoose &lt;a href=&#34;http://mongoosejs.com/&#34;&gt;http://mongoosejs.com/&lt;/a&gt; (modelling for mongodb)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The outcome of this is a PDF generation feature where the content can be easily modified with html (and Handlebars templating), and the style can easily be modified with CSS.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transforming the Enterprise with Node.js </title>
      <link>http://feedhenrydevblogarchive.github.io/transforming-enterprise-node-js-feedhenry/</link>
      <pubDate>Wed, 04 Dec 2013 18:11:23 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/transforming-enterprise-node-js-feedhenry/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;&lt;em&gt;By Damian Beresford - Engineering. Conor O&amp;rsquo;Neill - Product Management. Joe O&amp;rsquo;Reilly - Solutions Architecture.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Node.js has gone in a few short years from an interesting twist on server-side JavaScript to the engine of change in Enterprise Architecture. This blog post explores the market trends in using Node.js as a core tool for improving, mobilising and potentially migrating Enterprise legacy systems. It amalgamates our own experiences in integrating with legacy applications  and how we&amp;rsquo;ve helped our Enterprise customers begin the mobilisation of legacy systems and evaluate candidates for moving to a next generation platform. It also draws upon recent case studies and conference talks from companies such as PayPal, Walmart, Ebay, Groupon, etc who are using Node.js in production to run their businesses.&lt;/p&gt;

&lt;h2 id=&#34;mobile&#34;&gt;Mobile&lt;/h2&gt;

&lt;p&gt;Mobile is the chief driving force behind new requirements for these Enterprise Systems. The internal and external demands for attractive, high-performance apps increases daily. The work force also expects all internal systems (web applications in particular) to work well on mobile phones and tablets. Current systems are struggling to keep up with this flood of mobile requirements and the cutting edge technology demanded of them.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/12/Traditional_Mobilisation.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/12/Traditional_Mobilisation.png&#34; alt=&#34;Traditional_Mobilisation&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fig 1: Traditional mobilisation of an existing Enterprise System&lt;/p&gt;

&lt;h2 id=&#34;node-js-as-an-emerging-best-of-breed-enterprise-solution&#34;&gt;Node.js as an emerging best-of-breed Enterprise solution&lt;/h2&gt;

&lt;p&gt;FeedHenry provides a Mobile Application Platform which provides all of the end-to-end tools and infrastructure you need to build Cloud-powered Mobile Apps. Node is a critical part of our platform and enables our customers to connect mobile apps to complex Enterprise systems without drama.&lt;/p&gt;

&lt;p&gt;We fundamentally believe that Node.js is the best tool for enabling organizations to meet the requirements of cutting edge Enterprise Mobile development. We, among many others, find Node.js to be an order of magnitude faster than other tools for developing services.&lt;/p&gt;

&lt;p&gt;We highly recommend you watch this &amp;ldquo;&lt;a href=&#34;http://www.youtube.com/watch?v=V5yk5SZxWX4&#34;&gt;Releasing the Kraken&lt;/a&gt;&amp;rdquo; video by PayPal&amp;rsquo;s Bill Scott at the recent Nodeconf EU which FeedHenry sponsored. Some of his metrics around efficiencies gained are genuinely shocking. Also check out the great post about it on the &lt;a href=&#34;http://www.nearform.com/nodecrunch/?p=109&#34;&gt;nearForm blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Jeff Harrell of PayPal has followed it up &lt;a href=&#34;https://www.paypal-engineering.com/2013/11/22/node-js-at-paypal/&#34;&gt;with another post&lt;/a&gt; and Eran Hammer of Walmart &lt;a href=&#34;https://twitter.com/search?q=%23nodebf%20%40eranhammer&amp;amp;src=typd&#34;&gt;live-tweeted&lt;/a&gt; the zero-drama nature of running all of their mobile traffic through Node on Black Friday. &lt;/p&gt;

&lt;h2 id=&#34;legacy-systems-node-proxy-as-a-first-step&#34;&gt;Legacy Systems - Node Proxy as a first step&lt;/h2&gt;

&lt;p&gt;Node can initially be used to implement the &amp;lsquo;&lt;a href=&#34;http://www.eaipatterns.com/SmartProxy.html&#34;&gt;Smart Proxy&lt;/a&gt;&amp;rsquo; pattern which can be applied to migrating requests from an old System to new System services. Node.js makes for a highly efficient request proxy. The idea here is that Node sits in front of your existing Enterprise Systems (usually a portal server, e.g. Apache/Tomcat) and simply routes http traffic to its correct destination.This pattern also helps with API backward compatibility, e.g. for a new service that replaces a part of the old System.&lt;/p&gt;

&lt;p&gt;From a development perspective, the first version of Proxy can be a simple pass-through, i.e. just forward each request to the back end without any routing/modification. Not only will this give you a foothold in production, but also confidence that there is only a minimal performance overhead with the proxy (~10 milliseconds).&lt;/p&gt;

&lt;p&gt;As a bonus here, the Proxy can log all API requests to the backend allowing you to effectively see what parts of the backend API are being used most frequently. Once the initial version is embedded in Production, it’s then time to start routing requests to new services and start consolidating API’s from various different sources.&lt;/p&gt;

&lt;h2 id=&#34;node-and-development-of-micro-business-services&#34;&gt;Node and development of micro business services&lt;/h2&gt;

&lt;p&gt;Node is purpose-built for developing small web services. In fact, even the &amp;ldquo;hello world&amp;rdquo; example on nodejs.org is a simple web server. And thanks to the Node community, a huge number of NPM modules exist for all sorts of integrations. There are also various Node.js based frameworks for assisting with micro service development, e.g. hapijs.com.&lt;/p&gt;

&lt;p&gt;In Node, these micro services should consist of several smaller component modules which are versioned and used in node via NPM. These modules can be shared with other services, also via NPM, allowing you to implement a truly &lt;em&gt;component-based architecture&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Architecturally, depending on your system boundaries, these business services may be new business requirements, or replacing a part of the old System that had heavy technical debt. Also bear in mind that you may never get to replace all of an old System, due to legal or other complications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/12/Proxy_Micro_services_03.png&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/12/Proxy_Micro_services_03.png&#34; alt=&#34;Proxy_Micro_services_03&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fig 2: Moving to proxying and micro-services with Node&lt;/p&gt;

&lt;h2 id=&#34;enterprise-system-migration&#34;&gt;Enterprise System Migration&lt;/h2&gt;

&lt;p&gt;CIOs are under constant pressure to deliver new mobility-focused services whilst preserving the integrity of existing mission-critical systems.  Many Enterprise systems are well architected, resilient and scalable under load but many others can be monolithic and brittle in nature, fuelled by years of entropy.&lt;/p&gt;

&lt;p&gt;Organizations often mitigate risk by having long and complicated change approval processes and test-release cycles. The systems become ever-more-difficult to change and extend, particularly for core system modules which are essential to overall system stability. It is a serious challenge facing Enterprises to be able to meet high velocity requirements and drive the business forward.&lt;/p&gt;

&lt;p&gt;However, these existing systems are the foundation of the Enterprise’s business, and are typically what generates revenue. Migrating large Enterprise Systems in one large rewrite rarely works out well. Typically this is done by forming a new team, who plan to deliver ‘like for like’ functionality in a ‘greenfield’ environment. Often new teams under-estimate the size/complexity of the old system and fail to deliver. Meanwhile, the old system has been held together by a skeletal team, and overall the migration effort has been an expensive set-back to the business.&lt;/p&gt;

&lt;p&gt;Instead of the big rewrite, we have found that working with the old system from the start, and then creating new micro-services built around it, is a more successful approach. This is sometimes referred to as a ‘brownfield’ development effort. These new services are then either replacement parts of the old System, or services purpose-built for new business requirements.&lt;/p&gt;

&lt;p&gt;Eventually over time, the old system can get smaller and less core to the overall architecture, whilst these new micro-services grow more numerous in number and also in depth of functionality.&lt;/p&gt;

&lt;p&gt;Having smaller decoupled, autonomous micro-services is a more desirable modern architecture. It allows for quicker development and testing, less risk on production stability, and faster/better turnaround of requirements, allowing the development teams to focus on adding business value.&lt;/p&gt;

&lt;h2 id=&#34;flexible-cloud-hosted-node-js-backend&#34;&gt;Flexible Cloud-hosted Node.js backend&lt;/h2&gt;

&lt;p&gt;FeedHenry made the move to Node.js a long time ago (in Node years) at the beginning of 2011 when it was at v0.4. Our flexible Node-powered backend enables you to quickly and easily develop Node.js services that can interact with your existing business systems on one side and your mobile apps on the other. Using the FeedHenry cloud, you don’t need to expose your existing systems directly on the internet in order to interact with mobile applications. Instead, your mobile applications talk to the proven robust, scalable infrastructure of the FeedHenry Cloud which then talks securely to your backend systems.&lt;/p&gt;

&lt;p&gt;This pattern is in active use today by all of our customers including a major UK rail infrastructure company, a leading airline, large UK utility companies and Government agencies. In every case, existing systems provide both the data sources and sinks for totally new mobile applications with all of the necessary management and manipulation happening securely in the Node.js business logic.&lt;/p&gt;

&lt;h2 id=&#34;professional-services-consultancy&#34;&gt;Professional Services/Consultancy&lt;/h2&gt;

&lt;p&gt;Our long history with Node is critically important to your business success. Rather than being just another hot technology that has attracted bandwagon-jumpers, we made the strategic decision several years ago that Node should be at the heart of everything we do. In addition to a battle-hardened Node infrastructure, we also have a battle-hardened Professional Services team who have been delivering high-performance robust resilient Node-powered mobile solutions for many years.&lt;/p&gt;

&lt;p&gt;But they provide far more than point-solutions and can take you on the journey we have described above from initial micro-services and mobile applications to our full Mobile Application Platform. Our PS team understands that mobility is not just about Apps. By taking a strategic platform approach, they can guide you through the architectural, process and implementation decisions you need to make, to put mobility and agility at the heart of your enterprise and transform your business.&lt;/p&gt;

&lt;h2 id=&#34;large-enterprises-making-the-transition-to-node-js&#34;&gt;Large Enterprises making the transition to Node.js&lt;/h2&gt;

&lt;p&gt;The velocity of Node.js through the software development community has frankly been jaw-dropping. We have never before seen any tech become so important so quickly to so many businesses. What is even more shocking is how large corporations have embraced it and have begun evangelising it both internally and externally. They are doing so because of one reason - Node is transforming the Enterprise.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://engineering.groupon.com/2013/node-js/geekon-i-tier/&#34;&gt;Groupon&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.ebaytechblog.com/2013/05/17/how-we-built-ebays-first-node-js-application/&#34;&gt;eBay&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://venturebeat.com/2012/01/24/why-walmart-is-using-node-js/&#34;&gt;Walmart&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nearform.com/nodecrunch/how-node-js-has-revolutionized-the-mailonline#.UpS7eMRdV8E&#34;&gt;The Daily Mail&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nodered.org/&#34;&gt;IBM&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://venturebeat.com/2011/08/16/linkedin-node/&#34;&gt;LinkedIn&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/gblock/node-js-enterprise-class&#34;&gt;Microsoft&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And &lt;a href=&#34;http://nodejs.org/industry/&#34;&gt;many many more&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;By using Node.js in a step-wise fashion, large Enterprises can move at a pace that works for their organisation. A mobility strategy using Node in the modes we have described above can eventually lead to fundamental changes in how you deliver services to your employees and customers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Managing and understanding your Cloud Environments in the FeedHenry platform</title>
      <link>http://feedhenrydevblogarchive.github.io/managing-and-understanding-your-cloud-environments-in-the-feedhenry-platform/</link>
      <pubDate>Wed, 09 Oct 2013 12:53:51 +0000</pubDate>
      
      <guid>http://feedhenrydevblogarchive.github.io/managing-and-understanding-your-cloud-environments-in-the-feedhenry-platform/</guid>
      <description>&lt;p&gt;Many MBaaS and Mobile Platform solutions provide you with black-box access to your cloud, making them completely inscrutable. You have no insight into or control over what the cloud parts of your applications are doing. Not so with FeedHenry. As an open platform we are always looking for ways to give our customers more management features in every aspect of their deployments.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s for this reason we know you are going to love our latest release which will be accessible to all our customers from today: Cloud Environments.&lt;/p&gt;

&lt;p&gt;Starting at the top level of the Cloud Environments Tab in the Studio, you can see your aggregated values for Apps, Memory, CPU and Storage in both your Development and Production environments for all your Node.js code.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env1.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env1.jpg&#34; alt=&#34;env1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Drilling down into one of the Environments, you can then see Memory, CPU and Disk graphed over time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env2.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env2.jpg&#34; alt=&#34;env2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Drilling down into memory shows you the detailed App breakdown.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env8.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env8.jpg&#34; alt=&#34;env8&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And of course the same is available for CPU and Disk:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env6.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env6.jpg&#34; alt=&#34;env6&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env9.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env9.jpg&#34; alt=&#34;env9&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Apps Tab gives you a full list of Apps and their top-level information:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env3.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env3.jpg&#34; alt=&#34;env3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clicking on an individual App gives you full control over it including Start, Stop, and Undeploy.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/cloud_envs5.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/cloud_envs5.jpg&#34; alt=&#34;cloud_envs5&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And finally, not forgetting the cache.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env4.jpg&#34;&gt;&lt;img src=&#34;http://feedhenrydevblogarchive.github.io/wp-content/uploads/2013/10/env4.jpg&#34; alt=&#34;env4&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is just one part of a suite of functionality we have been releasing recently to make the lives of Developers and Ops people much easier. We&amp;rsquo;ll be announcing even more in the coming weeks.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>